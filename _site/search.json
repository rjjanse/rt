[
  {
    "objectID": "using.html",
    "href": "using.html",
    "title": "Using data",
    "section": "",
    "text": "Now that we have seen some basic R operations, such as functions and creating some data, let’s see some ways to access this data and play with it. For this we’ll mainly be working with dataframes and matrices. As an example, we will use the iris dataset, which is loaded into R by default. You can view the data just by running iris in your console:\n\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\nAlthough this is fine for small datasets, and seems okay for the iris datset, data will easily be too large to properly display in the console. In that case, we can choose to see only the beginning or the end of the data, using the head() and tail() functions. With these functions, you can specify the number of rows in a certain dataset that you want to see. For example, to see the first 4 and the last 5 rows of the iris dataset, we can do the following:\n\nhead(iris, n = 4)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n\ntail(iris, n = 5)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\n\n\n\n\n\n\nNote that because iris is loaded in by default, it does not appear in your global environment. To have it appear there, you can simply run:\niris &lt;- iris\nor use the data() function:\ndata(iris)\n\n\n\nThis is already much clearer. Nonetheless, we might want to see the whole data, for example to quickly look for inconsistencies. You can do this just by clicking on the name of the data in your global environment, or by using the view() function:\nview(iris)\nWhen we use view() or open data from the global environment, RStudio offers as some quick tools to get a better overview of our data. After opening the data, you will see something similar to Figure 1, where you can see some areas of interest demarcated.\n\n\n\n\n\n\nFigure 1: Viewing data\n\n\n\nWe can now scroll through the data and see all columns. If you wonder how many rows and columns you have, you can see this at the bottom of the window. The viewer will only show 50 columns at a time, but you can click through the columns if you have more than 50. If you want to see only entries that meet a certain condition, you can press the filter button at the top of the viewer to filter certain values. Lastly, you can sort a column as ascending or descending by clicking on the little arrows to the right of the column name. Note that any operation you perform on the data in the viewer (sorting, filtering), does not affect the actual data, only the data you see. In other words, you only manipulate what you see in the data, not the data itself.",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#viewing-data",
    "href": "using.html#viewing-data",
    "title": "Using data",
    "section": "",
    "text": "Now that we have seen some basic R operations, such as functions and creating some data, let’s see some ways to access this data and play with it. For this we’ll mainly be working with dataframes and matrices. As an example, we will use the iris dataset, which is loaded into R by default. You can view the data just by running iris in your console:\n\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\nAlthough this is fine for small datasets, and seems okay for the iris datset, data will easily be too large to properly display in the console. In that case, we can choose to see only the beginning or the end of the data, using the head() and tail() functions. With these functions, you can specify the number of rows in a certain dataset that you want to see. For example, to see the first 4 and the last 5 rows of the iris dataset, we can do the following:\n\nhead(iris, n = 4)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n\ntail(iris, n = 5)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\n\n\n\n\n\n\nNote that because iris is loaded in by default, it does not appear in your global environment. To have it appear there, you can simply run:\niris &lt;- iris\nor use the data() function:\ndata(iris)\n\n\n\nThis is already much clearer. Nonetheless, we might want to see the whole data, for example to quickly look for inconsistencies. You can do this just by clicking on the name of the data in your global environment, or by using the view() function:\nview(iris)\nWhen we use view() or open data from the global environment, RStudio offers as some quick tools to get a better overview of our data. After opening the data, you will see something similar to Figure 1, where you can see some areas of interest demarcated.\n\n\n\n\n\n\nFigure 1: Viewing data\n\n\n\nWe can now scroll through the data and see all columns. If you wonder how many rows and columns you have, you can see this at the bottom of the window. The viewer will only show 50 columns at a time, but you can click through the columns if you have more than 50. If you want to see only entries that meet a certain condition, you can press the filter button at the top of the viewer to filter certain values. Lastly, you can sort a column as ascending or descending by clicking on the little arrows to the right of the column name. Note that any operation you perform on the data in the viewer (sorting, filtering), does not affect the actual data, only the data you see. In other words, you only manipulate what you see in the data, not the data itself.",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#comparing-values",
    "href": "using.html#comparing-values",
    "title": "Using data",
    "section": "Comparing values",
    "text": "Comparing values\nBefore we see how to access the data, let’s take a sidestep to see how we can compare values in R. To compare values and get returned TRUE or FALSE (called Booleans) there are some important operators:\n\n&gt;: Greater than; is the value before the operator greater than the value after the operator.\n&lt;: Smaller than; is the value before the operator smaller than the value after the operator.\n&gt;=: Greater than or equal to; is the value before the operator greater than or equal to the value after the operator.\n&lt;=: Smaller than or equal to; is the value before the operator smaller than or equal to the value after the operator.\n==: Equal; is the value before the operator equal to the value after the operator.\n!=: Not equal; is the value before the operator not equal to the value after the operator.\n\nLet’s see some examples of using these operators:\n\n# Greater than\n5 &gt; 3\n\n[1] TRUE\n\n# Smaller than\n3 &lt; 5\n\n[1] TRUE\n\n# Greater than or equal to\n3 &gt;= 3\n\n[1] TRUE\n\n# Smaller than or equal to\n3 &lt;= 5\n\n[1] TRUE\n\n# Equal\n3 == 3\n\n[1] TRUE\n\n# Not equal\n3 != 3\n\n[1] FALSE",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#boolean-operators",
    "href": "using.html#boolean-operators",
    "title": "Using data",
    "section": "Boolean operators",
    "text": "Boolean operators\nNow that we can compare values and get returned TRUE or FALSE, we can also make multiple comparisons using Boolean operators (also know as logical operators). If the conditions specified match, these will return TRUE, otherwise FALSE.\n\n|: OR; the value before or after the operator should be TRUE.\n&: AND; the values before and after the operator should be TRUE.\n!: NOT; the match should not be TRUE.\nxor(x, y): XOR; x or y but not x and y; if x is TRUE, y should be FALSE and vice versa.\n\nFigure 2 shows a visual explanation of the boolean operators, as shown in the book R for Data Science.\n\n\n\n\n\n\nFigure 2: Boolean operators\n\n\n\nUsing them works as follows:\n\n# OR\n3 == 3 | 3 != 3\n\n[1] TRUE\n\n# AND\n3 == 3 & 3 != 3\n\n[1] FALSE\n\n# NOT\n!(3 == 3)\n\n[1] FALSE\n\n# True XOR\nxor(TRUE, FALSE)\n\n[1] TRUE\n\n# False XOR\nxor(FALSE, FALSE)\n\n[1] FALSE",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#accessing-the-data",
    "href": "using.html#accessing-the-data",
    "title": "Using data",
    "section": "Accessing the data",
    "text": "Accessing the data\nBack to accessing the data! We now have a data frame with data inside, loaded in our environment. However, how can we actually access that data? For that, we can ‘subset’ the data. There is three ways we can do that:\n\nDollar operator: $\nThe dollar operator, $, allows you to quickly subset a column from the data. This is a good way to have a quick look in your data. For example, if we want to subset the column Sepal.Length, we can simply do the following:\n\niris$Sepal.Length\n\n  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1\n [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0\n [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5\n [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1\n [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5\n [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3\n[109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2\n[127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8\n[145] 6.7 6.7 6.3 6.5 6.2 5.9\n\n\nAs you can see, this returns a vector with the values.\n\n\nSingle brackets: []\nImagine we want a specific row, a specific column, or even a specific cell from our data. In that case, $ is insufficient. Luckily, we can use single brackets: []. When using single brackets on a data frame, we can put two things in-between the brackets: the row-number we are interested in and the column we are interested in. These can be both index numbers and row/column names. If we want to select all rows or all columns, we can leave that argument empty. Let’s see some examples:\n\n# Select the value in the 14th row and 4th column\niris[14, 4]\n\n[1] 0.1\n\n# Select the second column by name with all rows\niris[, \"Sepal.Width\"]\n\n  [1] 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5\n [19] 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\n [37] 3.5 3.6 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\n [55] 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8\n [73] 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5\n [91] 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9\n[109] 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\n[127] 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2\n[145] 3.3 3.0 2.5 3.0 3.4 3.0\n\n# Select the value in the 11th row and 4th column by index and name\niris[11, \"Petal.Width\"]\n\n[1] 0.2\n\n\n\n\n\n\n\n\nMeow?\n\n\n\n\n\nWhile writing this tutorial, my cat walked on my keyboard and decided she wanted to add the following:\nckxcccccccccccccccccccccccccccccccccccccc[[[[[[[[‘xcccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc.9¿’]]]]]]]]\n\n\n\nNow we can go even further with our brackets. When we subset our data frame once, we get a vector of values. Imagine we want to subset the 4th value of the column Sepal.Width, we can simply do:\n\niris[, \"Sepal.Width\"][4]\n\n[1] 3.1\n\n\nHowever, our fun doesn’t stop here! What if we didn’t want the 4th value, but all values larger than 3.0? Easy; let’s see how it works:\n\n# We can get a vector of the column Sepal.Width as we saw before\niris[, \"Sepal.Width\"]\n\n  [1] 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5\n [19] 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\n [37] 3.5 3.6 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\n [55] 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8\n [73] 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5\n [91] 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9\n[109] 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\n[127] 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2\n[145] 3.3 3.0 2.5 3.0 3.4 3.0\n\n# From this vector, we can get per value a Boolean (TRUE or FALSE) whether it is &gt;3.0\niris[, \"Sepal.Width\"] &gt; 3\n\n  [1]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE\n [13] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [25]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[109] FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE\n[121]  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE\n[133] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n[145]  TRUE FALSE FALSE FALSE  TRUE FALSE\n\n# We can use these Booleans to subset the column to only keep values &gt;3.0\niris[, \"Sepal.Width\"][iris[\"Sepal.Width\"] &gt; 3]\n\n [1] 3.5 3.2 3.1 3.6 3.9 3.4 3.4 3.1 3.7 3.4 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6\n[20] 3.3 3.4 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.6 3.4 3.5 3.2 3.5 3.8\n[39] 3.8 3.2 3.7 3.3 3.2 3.2 3.1 3.3 3.1 3.2 3.4 3.1 3.3 3.6 3.2 3.2 3.8 3.2 3.3\n[58] 3.2 3.8 3.4 3.1 3.1 3.1 3.1 3.2 3.3 3.4\n\n## To make it more readable, we could of course store the Booleans in their own vector which we use to subset\n# Create vector with Booleans\nlarger_than_3 &lt;- iris[, \"Sepal.Width\"] &gt; 3\n\n# Subset Sepal.Width\niris[, \"Sepal.Width\"][larger_than_3]\n\n [1] 3.5 3.2 3.1 3.6 3.9 3.4 3.4 3.1 3.7 3.4 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6\n[20] 3.3 3.4 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.6 3.4 3.5 3.2 3.5 3.8\n[39] 3.8 3.2 3.7 3.3 3.2 3.2 3.1 3.3 3.1 3.2 3.4 3.1 3.3 3.6 3.2 3.2 3.8 3.2 3.3\n[58] 3.2 3.8 3.4 3.1 3.1 3.1 3.1 3.2 3.3 3.4\n\n\n\n\nDouble brackets: [[]]\nInstead of single brackets, we can also use double brackets. So what is the difference? First of all, we can supply only one argument to [[]]. In the case of a data frame, this means we cannot subset certain rows, but we can still subset columns. In a vector, we can use [[]] as seen before. So what is the difference between single brackets ([]) and double brackets ([[]])?\nIn vectors and matrices, using double brackets instead of single brackets will drop any attributes and names attached to the data (such as column labels). To subset on a list, double brackets can be used for single values/elements while single brackets return a list of the elements. You may notice that the difference is not big, but it is still good to have heard about it once. More can be found here.\n\n\n\n\n\n\nAlthough the $ operator is a quick way to access some data, it is recommended to not use it in the actual scripts you write. You can use $ to check out some data in the console or have quickly check something, but in your script you should use [] or [[]]. This allows you to easily transform code into your own functions (which we will see later). Additionally, dollar operators do not allow logicals, while brackets do.",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#which",
    "href": "using.html#which",
    "title": "Using data",
    "section": "Which",
    "text": "Which\nWhat if we wanted to know not the exact values greater than 3, but the row numbers in the data set? In that case, we could use which():\n\nwhich(iris[, \"Sepal.Width\"] &gt; 3)\n\n [1]   1   3   4   5   6   7   8  10  11  12  15  16  17  18  19  20  21  22  23\n[20]  24  25  27  28  29  30  31  32  33  34  35  36  37  38  40  41  43  44  45\n[39]  47  48  49  50  51  52  53  57  66  71  86  87 101 110 111 116 118 121 125\n[58] 126 132 137 138 140 141 142 144 145 149\n\n\nWe now have the line numbers with which (pun intended) we can subset those values:\n\niris[which(iris[, \"Sepal.Width\"] &gt; 3), \"Sepal.Width\"]\n\n [1] 3.5 3.2 3.1 3.6 3.9 3.4 3.4 3.1 3.7 3.4 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6\n[20] 3.3 3.4 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.6 3.4 3.5 3.2 3.5 3.8\n[39] 3.8 3.2 3.7 3.3 3.2 3.2 3.1 3.3 3.1 3.2 3.4 3.1 3.3 3.6 3.2 3.2 3.8 3.2 3.3\n[58] 3.2 3.8 3.4 3.1 3.1 3.1 3.1 3.2 3.3 3.4\n\n\nWe can even use our Boolean operators to show that using which() gives the same results as we saw before when not using which():\n\niris[which(iris[, \"Sepal.Width\"] &gt; 3), \"Sepal.Width\"] == iris[, \"Sepal.Width\"][iris[\"Sepal.Width\"] &gt; 3]\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nThe main advantage of which() is that it might be more readable in your code.",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#mutating-data",
    "href": "using.html#mutating-data",
    "title": "Using data",
    "section": "Mutating data",
    "text": "Mutating data\nIt is great to be able to subset specific data from our data frames, but it is much more fun to do some statistics with it! A great thing about the subsetted columns of data is that you can easily perform calculations on them.\nFor example, to multiply all values in in the column Sepal.Width by 3, we can simply do:\n\niris[[\"Sepal.Width\"]] * 3\n\n  [1] 10.5  9.0  9.6  9.3 10.8 11.7 10.2 10.2  8.7  9.3 11.1 10.2  9.0  9.0 12.0\n [16] 13.2 11.7 10.5 11.4 11.4 10.2 11.1 10.8  9.9 10.2  9.0 10.2 10.5 10.2  9.6\n [31]  9.3 10.2 12.3 12.6  9.3  9.6 10.5 10.8  9.0 10.2 10.5  6.9  9.6 10.5 11.4\n [46]  9.0 11.4  9.6 11.1  9.9  9.6  9.6  9.3  6.9  8.4  8.4  9.9  7.2  8.7  8.1\n [61]  6.0  9.0  6.6  8.7  8.7  9.3  9.0  8.1  6.6  7.5  9.6  8.4  7.5  8.4  8.7\n [76]  9.0  8.4  9.0  8.7  7.8  7.2  7.2  8.1  8.1  9.0 10.2  9.3  6.9  9.0  7.5\n [91]  7.8  9.0  7.8  6.9  8.1  9.0  8.7  8.7  7.5  8.4  9.9  8.1  9.0  8.7  9.0\n[106]  9.0  7.5  8.7  7.5 10.8  9.6  8.1  9.0  7.5  8.4  9.6  9.0 11.4  7.8  6.6\n[121]  9.6  8.4  8.4  8.1  9.9  9.6  8.4  9.0  8.4  9.0  8.4 11.4  8.4  8.4  7.8\n[136]  9.0 10.2  9.3  9.0  9.3  9.3  9.3  8.1  9.6  9.9  9.0  7.5  9.0 10.2  9.0\n\n\nWe can also multiply all values by a value specific to them. For example. to multiply Sepal.Width by Sepal.Length, we could run:\n\niris[[\"Sepal.Width\"]] * iris[[\"Sepal.Length\"]]\n\n  [1] 17.85 14.70 15.04 14.26 18.00 21.06 15.64 17.00 12.76 15.19 19.98 16.32\n [13] 14.40 12.90 23.20 25.08 21.06 17.85 21.66 19.38 18.36 18.87 16.56 16.83\n [25] 16.32 15.00 17.00 18.20 17.68 15.04 14.88 18.36 21.32 23.10 15.19 16.00\n [37] 19.25 17.64 13.20 17.34 17.50 10.35 14.08 17.50 19.38 14.40 19.38 14.72\n [49] 19.61 16.50 22.40 20.48 21.39 12.65 18.20 15.96 20.79 11.76 19.14 14.04\n [61] 10.00 17.70 13.20 17.69 16.24 20.77 16.80 15.66 13.64 14.00 18.88 17.08\n [73] 15.75 17.08 18.56 19.80 19.04 20.10 17.40 14.82 13.20 13.20 15.66 16.20\n [85] 16.20 20.40 20.77 14.49 16.80 13.75 14.30 18.30 15.08 11.50 15.12 17.10\n [97] 16.53 17.98 12.75 15.96 20.79 15.66 21.30 18.27 19.50 22.80 12.25 21.17\n[109] 16.75 25.92 20.80 17.28 20.40 14.25 16.24 20.48 19.50 29.26 20.02 13.20\n[121] 22.08 15.68 21.56 17.01 22.11 23.04 17.36 18.30 17.92 21.60 20.72 30.02\n[133] 17.92 17.64 15.86 23.10 21.42 19.84 18.00 21.39 20.77 21.39 15.66 21.76\n[145] 22.11 20.10 15.75 19.50 21.08 17.70\n\n\nIt is important to realize that if you are calculating with columns, each mutating value has to be of the same length as the column, or of length 1. If the mutating value is of the same length as the column (e.g., another column), each row in one column is mutated with the row in the other column. If the mutating value is of length 1 (e.g., the number 3), all rows in one column are mutated by the same value.\nYou can also perform functions on subsetted data:\n\nsummary(iris[[\"Sepal.Width\"]])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.000   2.800   3.000   3.057   3.300   4.400",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#adding-data-together",
    "href": "using.html#adding-data-together",
    "title": "Using data",
    "section": "Adding data together",
    "text": "Adding data together\nImagine we had two separate data sets: one with all data where the species is setosa and one with all data where the species is versicolor:\n\n# Get setosa data\niris_setosa &lt;- iris[which(iris[[\"Species\"]] == \"setosa\"), ]\n\n# Get versicolor data\niris_versicolor &lt;- iris[which(iris[[\"Species\"]] == \"versicolor\"), ]\n\nIf we wanted to add these data frames together again, we can use rbind(), which binds rows together. For rbind(), the data frames have to have the same columns, although they do not have to be in the same order.\n\n# Bind data together\niris_setosa_versicolor &lt;- rbind(iris_setosa, iris_versicolor)\n\n# See available values for species\ntable(iris_setosa_versicolor[[\"Species\"]])\n\n\n    setosa versicolor  virginica \n        50         50          0 \n\n\nWe can do the same if we want to bind multiple columns together. In this case, the two data frames should have an equal amount of rows.\n\n# Keep only sepal columns of iris_setosa\niris_setosa_sepal &lt;- iris[, c(\"Sepal.Length\", \"Sepal.Width\")]\n\n# Keep only petal columns of iris_setosa\niris_setosa_petal &lt;- iris[, c(\"Petal.Length\", \"Petal.Width\")]\n\n# Add sepal and petal together again\niris_setosa &lt;- cbind(iris_setosa_sepal, iris_setosa_petal)\n\n# See first rows of the new data\nhead(iris_setosa)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n1          5.1         3.5          1.4         0.2\n2          4.9         3.0          1.4         0.2\n3          4.7         3.2          1.3         0.2\n4          4.6         3.1          1.5         0.2\n5          5.0         3.6          1.4         0.2\n6          5.4         3.9          1.7         0.4\n\n\nOf course, these examples seem futile as we split data and add it back together. However, rbind() and cbind() are useful functions when you want to join similar data from different sources.",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#get-and-assign",
    "href": "using.html#get-and-assign",
    "title": "Using data",
    "section": "Get and assign",
    "text": "Get and assign\nThe last important thing we should discuss about acessing the data are the functions get() and assign(). Although we can easily assign new data while writing our code (data &lt;- iris), at a certain point we might want to automate it (and later on we will see how to do that). In that case, the name of the data we want might vary. When a value might vary, such as a column, it is often possible to use strings, such as \"iris\". However, for assigning data, this does not work:\n\ndata &lt;- \"iris\"\ndata\n\n[1] \"iris\"\n\n\nWe just assigned the string \"iris\", instead of the data iris. In this case, assign() allows us to achieve our objective:\n\nassign(\"data\", iris)\nhead(data, n = 5)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n\n\nIn the same way, if we want to flexibly get data from the global environment, we can use get():\n\ndata &lt;- get(\"iris\")\nhead(data, n = 5)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#value-types",
    "href": "using.html#value-types",
    "title": "Using data",
    "section": "Value types",
    "text": "Value types\nThe last thing to discuss for now are value types. A few times we talked about strings, which is a specific type a value can have in R. The most important value types to know for now are:\n\nnumeric: a real number, for example 1.42, 8.42, and -5.0.\ninteger: an integer, for exapmle 4, -3, and 7. In R, an integer is made explicit with L, for example: 10L.\ndate: a date, such as 2000-02-09, 2000-02-29, and 1912-06-23. Dates are stored behind the scene as an integer showing the distance from a set date. In R, this date is generally 1970-01-01, also known as the origin. Dates in R are generally written in the format yyyy-mm-dd.\nstring: a text, for example “hello”, “4”, or “==”. Strings are always enclosed with single or double quotation marks (’, “).\nlogical: a Boolean; TRUE or FALSE.\n\nTo check the type of a value, we can use class():\n\nclass(3)\n\n[1] \"numeric\"\n\nclass(3L)\n\n[1] \"integer\"\n\nclass(\"3\")\n\n[1] \"character\"\n\n\nAdditionally, we can transform values into different types, using certain functions:\n\nas.numeric(): transform value to numeric.\nas.integer(): transform value to integer.\nas.character(): transform value to string\nas.Date(): transform value to date. This function often needs an origin supplied. Note that Date is written with a capital D.\n\nHere are some examples:\n\nas.numeric(\"5\")\n\n[1] 5\n\nas.integer(3.9)\n\n[1] 3\n\nas.character(7)\n\n[1] \"7\"\n\nas.Date(\"1992-06-06\", origin = \"1970-01-01\")\n\n[1] \"1992-06-06\"",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#exercises",
    "href": "using.html#exercises",
    "title": "Using data",
    "section": "Exercises",
    "text": "Exercises\n\n1. Store new data\nBesides the dataset iris, another available dataset in R is mtcars. Load this data into a new data frame called data using assign().\n\n\nAnswer\nassign(\"data\", mtcars)\n\n\n\n\n2. Subset column\nNow subset the column disp and store this in a variable called var.\n\n\nAnswer\n# Use dollar operator (generally unrecommended)\nvar &lt;- data$disp\n\n# Use single brackets\nvar &lt;- data[, \"disp\"]\n\n# Use double brackets\nvar &lt;- data[[\"disp\"]]\n\n\n\n\n3. Keep certain values\nFrom the variable var, keep only values greater than 110.5 and store this in a variable called var_new.\n\n\nAnswer\n# With which()\nvar_new &lt;- var[which(var &gt; 110.5)]\n\n# Without which()\nvar_new &lt;- var[var &gt; 110.5]\n\n\n\n\n4. Mutate variables\nNow divided all values in var_new by 10 and store this in a variable called var_div.\n\n\nAnswer\nvar_div &lt;- var_new / 10\n\n\n\n\n5. Change values to character\nNow change the values in the variable var_div to character values and store these in a variable called var_char.\n\n\nAnswer\nvar_char &lt;- as.character(var_div)\n\n\n\n\n6. Check character type\nMake sure the first value in the variable var_char is not of the type numeric (called \"numeric\").\n\n\nAnswer\nclass(var_char[1]) != \"numeric\"\n\n\n[1] TRUE",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "using.html#next-topic",
    "href": "using.html#next-topic",
    "title": "Using data",
    "section": "Next topic",
    "text": "Next topic\nWe now know how we can access our data and manipulate it. Next up, we will learn about packages, which allows us to do so much more with our data then we have seen until now.\nNext: Packages",
    "crumbs": [
      "The basics",
      "Using data"
    ]
  },
  {
    "objectID": "tidyr.html",
    "href": "tidyr.html",
    "title": "Tidyr",
    "section": "",
    "text": "{tidyr} is a package from the tidyverse that is meant to help you tidy up your data. What is considered ‘tidy’ data can be read in vignette(\"tidy-data\"). In short, tidy data helps you use {dplyr} and other tidyverse tools in a way that lets you spend less time on structuring your data and more on performing your analyses.",
    "crumbs": [
      "Into the tidyverse",
      "Tidyr"
    ]
  },
  {
    "objectID": "tidyr.html#tidyr",
    "href": "tidyr.html#tidyr",
    "title": "Tidyr",
    "section": "",
    "text": "{tidyr} is a package from the tidyverse that is meant to help you tidy up your data. What is considered ‘tidy’ data can be read in vignette(\"tidy-data\"). In short, tidy data helps you use {dplyr} and other tidyverse tools in a way that lets you spend less time on structuring your data and more on performing your analyses.",
    "crumbs": [
      "Into the tidyverse",
      "Tidyr"
    ]
  },
  {
    "objectID": "tidyr.html#reshaping-data",
    "href": "tidyr.html#reshaping-data",
    "title": "Tidyr",
    "section": "Reshaping data",
    "text": "Reshaping data\n\nWide to long\nSome analyses require data in long format (i.e. one study participant can have multiple observations which are represented by multiple rows) while data might be retrieved in wide format (i.e. one study participant can have multiple observations which are represented by multiple columns). In such a case, {tidyr} offers us pivot_longer().\nWe can use pivot_longer() in a number of ways, but we must always supply the data in the argument data, and the columns to be pivoted in cols. In the simplest cases, this will suffice.\nAs an example, let’s look at billboard, a dataset available through {tidyr}. billboard contains songs ranking the top 100 in the year 2000 with their position in each week after entering the top 100 (wk).\n\n# Load tidyr\npacman::p_load(\"tidyr\")\n\n# What does billboard look like?\nhead(billboard)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n# Pivot billboard to long format\nbillboard_long &lt;- pivot_longer(billboard, wk1:wk76)\n\n# Reprint billboard\nhead(billboard_long)\n\n# A tibble: 6 × 5\n  artist track                   date.entered name  value\n  &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt; &lt;dbl&gt;\n1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87\n2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82\n3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72\n4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77\n5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87\n6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94\n\n\nWe can see that the data now has much less columns (5 as opposed to 79 previously). Instead, the number of rows has been increased: each row now corresponds to a week for each song. The weeks were put into a column called ‘name’ by default, and the values that were in the original week columns went into a column called ‘value’ by default.\nWe can of course change the names of those columns:\n\n# Pivot billboard to long format\nbillboard_long &lt;- pivot_longer(billboard, wk1:wk76, names_to = \"week\", values_to = \"position\")\n\n# Reprint billboard\nhead(billboard_long)\n\n# A tibble: 6 × 5\n  artist track                   date.entered week  position\n  &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;    &lt;dbl&gt;\n1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1         87\n2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2         82\n3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3         72\n4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4         77\n5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5         87\n6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6         94\n\n\nCurrently, the week numbers are in the column called ‘week’, but are represented as a character string because the characters ‘wk’ are present in all columns. Although we will learn how to manipulate this in Regex, we can prevent this while calling the function:\n\n# Pivot billboard to long format\nbillboard_long &lt;- pivot_longer(billboard, wk1:wk76, names_to = \"week\", values_to = \"position\", names_prefix = \"wk\")\n\n# Reprint billboard\nhead(billboard_long)\n\n# A tibble: 6 × 5\n  artist track                   date.entered week  position\n  &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;chr&gt;    &lt;dbl&gt;\n1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   1           87\n2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   2           82\n3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   3           72\n4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   4           77\n5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   5           87\n6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   6           94\n\n\nAlthough we have numbers now, they are still of class ‘character’. However, we can specify the type they should be using names_transform:\n\n# Pivot billboard to long format\nbillboard_long &lt;- pivot_longer(billboard, wk1:wk76, names_to = \"week\", values_to = \"position\", names_prefix = \"wk\", names_transform = as.numeric)\n\n# Reprint billboard\nhead(billboard_long)\n\n# A tibble: 6 × 5\n  artist track                   date.entered  week position\n  &lt;chr&gt;  &lt;chr&gt;                   &lt;date&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n1 2 Pac  Baby Don't Cry (Keep... 2000-02-26       1       87\n2 2 Pac  Baby Don't Cry (Keep... 2000-02-26       2       82\n3 2 Pac  Baby Don't Cry (Keep... 2000-02-26       3       72\n4 2 Pac  Baby Don't Cry (Keep... 2000-02-26       4       77\n5 2 Pac  Baby Don't Cry (Keep... 2000-02-26       5       87\n6 2 Pac  Baby Don't Cry (Keep... 2000-02-26       6       94\n\n\nThis kind of control gives us much less head-ache when, for instance, we want to use the data for plotting (for which we will discuss the code in Plotting):\n\n# Load packages\npacman::p_load(\"dplyr\",   # Data wrangling\n               \"ggplot2\"  # Data visualization\n)\n\n# Get only Britney Spears songs\ndat_plot &lt;- filter(billboard_long, artist == \"Spears, Britney\" & !is.na(position))\n\n# Create plot\nggplot(dat_plot, aes(x = week, y = position, colour = track)) +\n    # Geometries\n    geom_line() +\n    # Scaling\n    scale_x_continuous(limits = c(0, 20)) +\n    scale_y_continuous(limits = c(0, 100)) +\n    scale_colour_manual(values = c(\"#d3b866\", \"#e09373\", \"#e586b4\")) + \n    # Aesthetics\n    theme(panel.grid = element_blank(),\n          panel.background = element_rect(colour = \"#002b36\", fill = \"#002b36\"),\n          plot.background = element_rect(colour = \"#002b36\", fill = \"#002b36\"),\n          axis.text = element_text(colour = \"#dee2e6\"),\n          axis.title = element_text(colour = \"#dee2e6\"),\n          axis.line = element_line(colour = \"#dee2e6\"),\n          axis.ticks = element_line(colour = \"#dee2e6\"),\n          legend.text = element_text(colour = \"#dee2e6\"),\n          legend.title = element_blank(),\n          legend.background = element_rect(colour = \"#002b36\", fill = \"#002b36\"),\n          legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nLong to wide\nWe can also reshape data from longer to wider format using pivot_wider(). We can simply do this by defining which column contains the name and which column contains the values. We can append the final name of the columns using the names_prefix argument.\n\n# Pivot data to wider formar\nbillboard_wide &lt;- pivot_wider(billboard_long, names_from = week, values_from = position, names_prefix = \"wk\")\n\n# Preview data\nhead(billboard_wide)\n\n# A tibble: 6 × 79\n  artist      track date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8\n  &lt;chr&gt;       &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2 Pac       Baby… 2000-02-26      87    82    72    77    87    94    99    NA\n2 2Ge+her     The … 2000-09-02      91    87    92    NA    NA    NA    NA    NA\n3 3 Doors Do… Kryp… 2000-04-08      81    70    68    67    66    57    54    53\n4 3 Doors Do… Loser 2000-10-21      76    76    72    69    67    65    55    59\n5 504 Boyz    Wobb… 2000-04-15      57    34    25    17    17    31    36    49\n6 98^0        Give… 2000-08-19      51    39    34    26    26    19     2     2\n# ℹ 68 more variables: wk9 &lt;dbl&gt;, wk10 &lt;dbl&gt;, wk11 &lt;dbl&gt;, wk12 &lt;dbl&gt;,\n#   wk13 &lt;dbl&gt;, wk14 &lt;dbl&gt;, wk15 &lt;dbl&gt;, wk16 &lt;dbl&gt;, wk17 &lt;dbl&gt;, wk18 &lt;dbl&gt;,\n#   wk19 &lt;dbl&gt;, wk20 &lt;dbl&gt;, wk21 &lt;dbl&gt;, wk22 &lt;dbl&gt;, wk23 &lt;dbl&gt;, wk24 &lt;dbl&gt;,\n#   wk25 &lt;dbl&gt;, wk26 &lt;dbl&gt;, wk27 &lt;dbl&gt;, wk28 &lt;dbl&gt;, wk29 &lt;dbl&gt;, wk30 &lt;dbl&gt;,\n#   wk31 &lt;dbl&gt;, wk32 &lt;dbl&gt;, wk33 &lt;dbl&gt;, wk34 &lt;dbl&gt;, wk35 &lt;dbl&gt;, wk36 &lt;dbl&gt;,\n#   wk37 &lt;dbl&gt;, wk38 &lt;dbl&gt;, wk39 &lt;dbl&gt;, wk40 &lt;dbl&gt;, wk41 &lt;dbl&gt;, wk42 &lt;dbl&gt;,\n#   wk43 &lt;dbl&gt;, wk44 &lt;dbl&gt;, wk45 &lt;dbl&gt;, wk46 &lt;dbl&gt;, wk47 &lt;dbl&gt;, wk48 &lt;dbl&gt;, …\n\n\nThis returns the data to its original state (note that missings cannot be compared):\n\n# Compare all individual values in the data frames\ntable(billboard == billboard_wide, useNA = \"always\")\n\n\n TRUE  &lt;NA&gt; \n 6258 18785",
    "crumbs": [
      "Into the tidyverse",
      "Tidyr"
    ]
  },
  {
    "objectID": "tidyr.html#filling-in-nas",
    "href": "tidyr.html#filling-in-nas",
    "title": "Tidyr",
    "section": "Filling in NA’s",
    "text": "Filling in NA’s\n\nSingle value for a whole column\nSometimes, we have missing values in columns (i.e. NA’s), that we want to change. This can be due to some assumptions we have made (e.g. absence of a diagnostic code in a health record means absence of the corresponding disease), because we want to name our missings something different than NA, or because we otherwise know what these values should be (e.g. an artificial indicator).\nTo do this, we can use the function replace_na(), which allows us to specify what missing values should be for each individual column specified. As an example, we will change missing values in the billboard data to -1 for the weeks 20 and 21, to indicate the song was no longer in the top 100 in the week specified by that column.\n\n# Change NAs in weeks 66 and 67\nbillboard_replaced &lt;- replace_na(billboard, list(wk20 = -1, wk21 = -1))\n\n# Show that these values now exist where missing data first existed for week 20\ntable(billboard[[\"wk20\"]], useNA = \"always\"); table(billboard_replaced[[\"wk20\"]], useNA = \"always\")\n\n\n   2    3    4    5    6    7    9   10   11   12   14   15   16   18   19   20 \n   2    2    3    2    1    2    1    4    1    2    4    4    1    1    1    3 \n  21   22   23   25   26   28   30   33   34   35   39   40   42   43   45   46 \n   1    2    3    4    3    1    3    1    2    1    1    1    2    1    1    1 \n  48   49   50   51   53   54   56   58   59   61   62   66   67   68   69   70 \n   1    1    2    1    1    2    1    2    3    1    3    2    1    2    1    3 \n  71   72   74   77   78   79   82   83   84   85   86   87   88   89   90   91 \n   1    1    1    2    2    2    1    1    1    1    4    5    2    6    4    3 \n  92   93   94   95   96   97   98   99  100 &lt;NA&gt; \n   2    1    2    3    1    2    1    3    5  171 \n\n\n\n  -1    2    3    4    5    6    7    9   10   11   12   14   15   16   18   19 \n 171    2    2    3    2    1    2    1    4    1    2    4    4    1    1    1 \n  20   21   22   23   25   26   28   30   33   34   35   39   40   42   43   45 \n   3    1    2    3    4    3    1    3    1    2    1    1    1    2    1    1 \n  46   48   49   50   51   53   54   56   58   59   61   62   66   67   68   69 \n   1    1    1    2    1    1    2    1    2    3    1    3    2    1    2    1 \n  70   71   72   74   77   78   79   82   83   84   85   86   87   88   89   90 \n   3    1    1    1    2    2    2    1    1    1    1    4    5    2    6    4 \n  91   92   93   94   95   96   97   98   99  100 &lt;NA&gt; \n   3    2    1    2    3    1    2    1    3    5    0 \n\n\n\n\nBased on other values in column\nIn some cases, we want to copy the value of a certain column to other, missing rows in that column. As an example, this could be the case of biological sex at birth is recorded only in a first study visit, even though biological sex at birth remains constant over time (because birth only occurs once). For this, we can use the fill() function.\nThe fill() function allows us to fill the value in a column. We can specify one of four directions for how the filling occurrs. Note this example data:\n\n# Create example data for fill()\ndat_fill &lt;- tibble(id = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4),\n                   visit = rep(1:3, 4),\n                   bio_sex_birth = c(\"male\", NA, NA, NA, \"female\", NA, \n                                     NA, NA, NA, \"male\", NA, NA))\n\n# Show data\ndat_fill\n\n# A tibble: 12 × 3\n      id visit bio_sex_birth\n   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        \n 1     1     1 male         \n 2     1     2 &lt;NA&gt;         \n 3     1     3 &lt;NA&gt;         \n 4     2     1 &lt;NA&gt;         \n 5     2     2 female       \n 6     2     3 &lt;NA&gt;         \n 7     3     1 &lt;NA&gt;         \n 8     3     2 &lt;NA&gt;         \n 9     3     3 &lt;NA&gt;         \n10     4     1 male         \n11     4     2 &lt;NA&gt;         \n12     4     3 &lt;NA&gt;         \n\n\nWe can see that for three individuals, we know their biological sex at birth, for one individual, this information was recored at visit 2 (ID 2), and for one individual (ID 3), this information is missing. To fill in these missing values, we can use fill():\n\n# Fill missing values downwards\nfill(dat_fill, bio_sex_birth, .direction = \"down\")\n\n# A tibble: 12 × 3\n      id visit bio_sex_birth\n   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        \n 1     1     1 male         \n 2     1     2 male         \n 3     1     3 male         \n 4     2     1 male         \n 5     2     2 female       \n 6     2     3 female       \n 7     3     1 female       \n 8     3     2 female       \n 9     3     3 female       \n10     4     1 male         \n11     4     2 male         \n12     4     3 male         \n\n\nWhen the fill direction is down, we can see that each value is only filled in downwards. The downwards direction poses a problem for individual 2 that now switches biological sex at birth, which should not be possible.\n\n# Fill missing values upwards\nfill(dat_fill, bio_sex_birth, .direction = \"up\")\n\n# A tibble: 12 × 3\n      id visit bio_sex_birth\n   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        \n 1     1     1 male         \n 2     1     2 female       \n 3     1     3 female       \n 4     2     1 female       \n 5     2     2 female       \n 6     2     3 male         \n 7     3     1 male         \n 8     3     2 male         \n 9     3     3 male         \n10     4     1 male         \n11     4     2 &lt;NA&gt;         \n12     4     3 &lt;NA&gt;         \n\n\nWhen the fill direction is up, we just fill upwards, which means that individual 4 does not get their missing values filled in.\n\n# Fill missing values downwards then upwards\nfill(dat_fill, bio_sex_birth, .direction = \"downup\")\n\n# A tibble: 12 × 3\n      id visit bio_sex_birth\n   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        \n 1     1     1 male         \n 2     1     2 male         \n 3     1     3 male         \n 4     2     1 male         \n 5     2     2 female       \n 6     2     3 female       \n 7     3     1 female       \n 8     3     2 female       \n 9     3     3 female       \n10     4     1 male         \n11     4     2 male         \n12     4     3 male         \n\n\nThe direction downup simply means that first we fill downwards and then upwards, meaning that when the filling upwards occurs, there are already some NA’s filled in by the downward filling.\n\n# Fill missing values upwards then downwards\nfill(dat_fill, bio_sex_birth, .direction = \"updown\")\n\n# A tibble: 12 × 3\n      id visit bio_sex_birth\n   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        \n 1     1     1 male         \n 2     1     2 female       \n 3     1     3 female       \n 4     2     1 female       \n 5     2     2 female       \n 6     2     3 male         \n 7     3     1 male         \n 8     3     2 male         \n 9     3     3 male         \n10     4     1 male         \n11     4     2 male         \n12     4     3 male         \n\n\nThe updown direction is alike the downup direction, but just the other way around.\nImportantly however, all these directions fill also the missing values for individual 3, even though we do not know their actual value. This is why it is always important to evaluate whether you need to fill within a grouping structure. If we apply this here, we can see that both updown and downup give us the correct results:\n\n# Fill missing values\ndat_fill %&gt;%\n    # Arrange for grouping\n    arrange(id) %&gt;%\n    # Create groups out of individuals\n    group_by(id) %&gt;%\n    # Fill values downwards then upwards\n    fill(bio_sex_birth, .direction = \"downup\") %&gt;%\n    # Remove grouping structure\n    ungroup()\n\n# A tibble: 12 × 3\n      id visit bio_sex_birth\n   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        \n 1     1     1 male         \n 2     1     2 male         \n 3     1     3 male         \n 4     2     1 female       \n 5     2     2 female       \n 6     2     3 female       \n 7     3     1 &lt;NA&gt;         \n 8     3     2 &lt;NA&gt;         \n 9     3     3 &lt;NA&gt;         \n10     4     1 male         \n11     4     2 male         \n12     4     3 male         \n\n\nThere are also cases where we are only interested in filling values in a single direction only, such as when a measurement should only be available from a certain point onwards.",
    "crumbs": [
      "Into the tidyverse",
      "Tidyr"
    ]
  },
  {
    "objectID": "tidyr.html#exercises",
    "href": "tidyr.html#exercises",
    "title": "Tidyr",
    "section": "Exercises",
    "text": "Exercises\nFor these exercises, we will use the storms dataset available in {dplyr}.\n\n1. Continue storm category\nImagine that we want to say that a storm keeps their hurricane category, even after it ceases to be a hurricane. Tidy the data to portray this.\n\n\nAnswer\n# Fill the category downwards in grouped data\nstorms %&gt;%\n    # Arrange for grouping\n    arrange(name) %&gt;%\n    # Group per storm\n    group_by(name) %&gt;%\n    # Fill category downwards only\n    fill(category, .direction = \"down\") %&gt;%\n    # Remove grouping structure\n    ungroup() %&gt;%\n    ## Only to show what answer should look like\n    # Show storm Gladys as an example\n    filter(name == \"Gladys\") %&gt;%\n    # Print all rows\n    print(n = 46)\n\n\n# A tibble: 46 × 13\n   name    year month   day  hour   lat  long status     category  wind pressure\n   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Gladys  1975     9    22    18  10.3 -34.8 tropical …       NA    25     1012\n 2 Gladys  1975     9    23     0  10.6 -35.8 tropical …       NA    25     1012\n 3 Gladys  1975     9    23     6  11   -36.7 tropical …       NA    25     1012\n 4 Gladys  1975     9    23    12  11.4 -37.4 tropical …       NA    25     1012\n 5 Gladys  1975     9    23    18  11.7 -38.2 tropical …       NA    30     1010\n 6 Gladys  1975     9    24     0  12.1 -38.8 tropical …       NA    30     1010\n 7 Gladys  1975     9    24     6  12.4 -39.6 tropical …       NA    30     1010\n 8 Gladys  1975     9    24    12  12.9 -40   tropical …       NA    30     1010\n 9 Gladys  1975     9    24    18  13.5 -40.4 tropical …       NA    35     1005\n10 Gladys  1975     9    25     0  14.2 -41   tropical …       NA    40     1005\n11 Gladys  1975     9    25     6  14.8 -42   tropical …       NA    50     1000\n12 Gladys  1975     9    25    12  15.4 -43   tropical …       NA    60     1000\n13 Gladys  1975     9    25    18  15.8 -44   hurricane         1    65      990\n14 Gladys  1975     9    26     0  16.2 -45   hurricane         1    65      990\n15 Gladys  1975     9    26     6  16.4 -46.1 hurricane         1    65      990\n16 Gladys  1975     9    26    12  16.6 -47.7 hurricane         1    65      990\n17 Gladys  1975     9    26    18  16.8 -49.3 hurricane         1    65      990\n18 Gladys  1975     9    27     0  17.1 -50.7 hurricane         1    65      990\n19 Gladys  1975     9    27     6  17.6 -52.2 hurricane         1    65      990\n20 Gladys  1975     9    27    12  18.2 -53.7 hurricane         1    65      990\n21 Gladys  1975     9    27    18  18.8 -55.1 hurricane         1    65      990\n22 Gladys  1975     9    28     0  19.4 -56.4 hurricane         1    65      992\n23 Gladys  1975     9    28     6  19.6 -57.4 hurricane         1    65      992\n24 Gladys  1975     9    28    12  19.8 -58.2 hurricane         1    65     1000\n25 Gladys  1975     9    28    18  20.3 -59.3 hurricane         1    65      998\n26 Gladys  1975     9    29     0  21.2 -60.3 hurricane         1    65      995\n27 Gladys  1975     9    29     6  22.1 -61.4 hurricane         1    70      990\n28 Gladys  1975     9    29    12  23   -62.6 hurricane         1    70      990\n29 Gladys  1975     9    29    18  23.6 -63.9 hurricane         1    75      985\n30 Gladys  1975     9    30     0  24.1 -65.2 hurricane         1    80      975\n31 Gladys  1975     9    30     6  24.6 -66.5 hurricane         1    80      975\n32 Gladys  1975     9    30    12  25.1 -67.9 hurricane         1    80      975\n33 Gladys  1975     9    30    18  25.6 -69.3 hurricane         1    80      975\n34 Gladys  1975    10     1     0  26.1 -70.6 hurricane         1    80      975\n35 Gladys  1975    10     1     6  26.8 -71.7 hurricane         1    80      975\n36 Gladys  1975    10     1    12  27.9 -72.4 hurricane         1    80      975\n37 Gladys  1975    10     1    18  29.4 -73   hurricane         2    90      969\n38 Gladys  1975    10     2     0  31   -73   hurricane         3   100      954\n39 Gladys  1975    10     2     6  32.9 -72.1 hurricane         3   110      942\n40 Gladys  1975    10     2    12  35.3 -69.8 hurricane         4   120      939\n41 Gladys  1975    10     2    18  37.8 -67   hurricane         4   120      939\n42 Gladys  1975    10     3     0  40.8 -62.6 hurricane         3   110      950\n43 Gladys  1975    10     3     6  43.7 -57   hurricane         2    85      960\n44 Gladys  1975    10     3    12  46.6 -50.6 hurricane         2    85      960\n45 Gladys  1975    10     3    18  50.5 -45.5 extratrop…        2    75      975\n46 Gladys  1975    10     4     0  55   -40   extratrop…        2    65      980\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;\n\n\n\n\n2. Indicate non-hurricanes\nAs an alternative, set category to -1 if the storm was not a hurricane (and therefore the category is NA).\n\n\nAnswer\n# Set NA's to -1\nstorms_replaced &lt;- replace_na(storms, list(category = -1))\n\n# See categories in storms_replaced\ntable(storms_replaced[[\"category\"]], useNA = \"always\")\n\n\n\n   -1     1     2     3     4     5  &lt;NA&gt; \n14734  2548   993   593   553   116     0",
    "crumbs": [
      "Into the tidyverse",
      "Tidyr"
    ]
  },
  {
    "objectID": "tidyr.html#next-topic",
    "href": "tidyr.html#next-topic",
    "title": "Tidyr",
    "section": "Next topic",
    "text": "Next topic\nNow that we have seen how we tidy our data, the last thing left for us to discuss in the tidyverse is how to combine all these functions into efficient pipelines using {magrittr} and the pipe (%&gt;%).\nNext: Magrittr",
    "crumbs": [
      "Into the tidyverse",
      "Tidyr"
    ]
  },
  {
    "objectID": "rstudio.html",
    "href": "rstudio.html",
    "title": "RStudio",
    "section": "",
    "text": "One of the most popular IDEs for R is RStudio, developed by Posit. RStudio is an especially great IDE for R because it was developed specifically with R in mind. Although other IDEs exist, these are often more general, meaning there is functionality that is not relevant to R, or that there are implementations missing that could greatly benefit R users. Additionally, if you are ever interested in working with Python, RStudio also supports Python, as well as integration of Python and R into the same document.\nRStudio can be downloaded from https://posit.co/download/rstudio-desktop/. You have already downloaded R in the previous section so you can immediately go to step two and download RStudio desktop.",
    "crumbs": [
      "Set-up",
      "RStudio"
    ]
  },
  {
    "objectID": "rstudio.html#installing-the-rstudio-ide",
    "href": "rstudio.html#installing-the-rstudio-ide",
    "title": "RStudio",
    "section": "",
    "text": "One of the most popular IDEs for R is RStudio, developed by Posit. RStudio is an especially great IDE for R because it was developed specifically with R in mind. Although other IDEs exist, these are often more general, meaning there is functionality that is not relevant to R, or that there are implementations missing that could greatly benefit R users. Additionally, if you are ever interested in working with Python, RStudio also supports Python, as well as integration of Python and R into the same document.\nRStudio can be downloaded from https://posit.co/download/rstudio-desktop/. You have already downloaded R in the previous section so you can immediately go to step two and download RStudio desktop.",
    "crumbs": [
      "Set-up",
      "RStudio"
    ]
  },
  {
    "objectID": "rstudio.html#finding-your-way-around-rstudio",
    "href": "rstudio.html#finding-your-way-around-rstudio",
    "title": "RStudio",
    "section": "Finding your way around RStudio",
    "text": "Finding your way around RStudio\nNow let’s see what RStudio offers us compared to the graphical user interface of R itself. When we open RStudio, Figure 1 shows what we see:\n\n\n\n\n\n\nFigure 1: Default RStudio\n\n\n\n\nInterface\nFirst, let’s see what each section in the RStudio window, as numbered in Figure 2, means.\n\nThe first section is the script. In the script is where you will write most of your code. Scripts are text files that are saved on your device and you can load in later, meaning any code you write you can reuse later, without writing it again.\nThe second section is the console. Any code you run in the script will show its output in the console. Additionally, if you quickly want to see the output of some code, you can write it in the console instead of the script (but it won’t be saved then).\nThe third section is the global environment. Any data you create wil show up in here and from here you can inspect the data and details related to the data.\nThe fourth section contains multiple tabs, of which many are relevant to any R user.\n\nThe first tab is the ‘Files’ tab. When you are working on some code in R, it is possible to determine from where files are loaded and where files are saved by default. This location is automatically opened in the ‘Files’ tab, from where you can inspect the location and load any files by hand.\nThe second tab is the ‘Plots’ tab. Whenever you create a plot (i.e., figure) in R, it will show up in this tab, so that you can visually inspect whether you like it before exporting it.\nIn the third tab, ‘Packages’, you can find all Packages (more on those later) you have installed and see which ones are loaded. Additionally, you can update packages from this tab.\nThe ‘Help’ tab, the fourth of the tabs available, allows you to search for functions and packages and helps you understand how they work and how to enter data into them to obtain the desires results.\nThe last tab of interest for now, the ‘Viewer’ tab, allows you to view created documents. Sometimes, R allows you to documents, such as HTML documents (of which we will see an example later on), which can then be visually inspected in the viewer before export.\n\n\n\n\n\n\n\n\nFigure 2: RStudio interface\n\n\n\nThese are all the important sections and tabs any RStudio user should know about. Don’t worry if you don’t immediately understand or remember what the windows do or represent. Throughout the tutorial, they will come back and through practice you will get a good understanding of what you see in your RStudio window.\n\n\nSettings\nSecond, let’s highlight some good settings that can ease your programming in R. The settings I will highlight here are my personal preference and in no way something you must adhere to, but it is good to know that they exist and that get an idea of the extent to which you can personalize the way RStudio works for you.\nTo open the settings, you can go to ‘Tools’ in the menu bar at the top of the screen, and select ‘Global options’ in the drop-down menu, shown in Figure 3.\n\n\n\n\n\n\nFigure 3: Going to global options\n\n\n\n\nSaving the workspace\nA first setting I want to highlight is saving the workspace. By default, when you exit RStudio, RStudio will ask you whether you want to save the workspace. The saved workspace will then be restored upon re-opening R. In other words, any data you created and loaded in would be saved upon quitting RStudio and loaded back in when you start RStudio again. Although this may sound useful, it also means that all data you create needs to be removed manually. This can quickly cause problems with memory and the speed of R and your device. Therefore I suggest that under ‘General’ you remove the tick from ‘Restore .RData into workspace at startup’ and set Save workspace to .RData on exit to Never as seen in Figure 4.\n\n\n\n\n\n\nFigure 4: Workspace settings\n\n\n\n\n\nCode display\nTo make our code a bit more readable, I suggest changing a few settings under the section ‘Code’ in the tab ‘Display’ as seen in Figure 5. I prefer changing the following settings regarding my code display:\n\nMargin: by default, the scripts in R show a margin (a vertical line) on the right of a code. This can help you style your code width if you use RStudio on different devices with different screen widths. Personally, I like to turn the margin off by removing the tick from ‘Show margin’.\nScrolling past end: when you write a code in a script, you can scroll to the end of the script, but not further, However, personally I prefer to have the code that I am looking at be in the middle of the screen. By ticking ‘Allow scroll past end of document’, I can keep scrolling after the code finishes to center the code in the window.\nHighlight functions: in R, we can calculate many things using functions (more on this later). However, these normally are the same colour as the rest of your code. I prefer to highlight functions to increase readability. You can do this by ticking ‘Highlight R function calls’.\nRainbow parentheses: many of the code that is written in R uses parentheses: (). However, many parentheses within each other might become very confusing: (((()))). Although R highlights the corresponding parenthesis, I find it helpful to additionally colour corresponding parentheses the same colour, while non-corresponding parentheses are coloured different. You can do this by ticking ‘Rainbow parentheses’.\n\n\n\n\n\n\n\nFigure 5: Code display settings\n\n\n\n\n\nRStudio appearance\nWhen working in RStudio, I prefer the screen to not be too bright. Additionally, I modified the way the code looks to my own preferences. You can try what works best for you under ‘Appearance’ (Figure 6).\n\n\n\n\n\n\nFigure 6: RStudio appearance settings",
    "crumbs": [
      "Set-up",
      "RStudio"
    ]
  },
  {
    "objectID": "rstudio.html#next-topic",
    "href": "rstudio.html#next-topic",
    "title": "RStudio",
    "section": "Next topic",
    "text": "Next topic\nWith both R and RStudio set-up, let’s start using R.\nNext: Creating and storing data",
    "crumbs": [
      "Set-up",
      "RStudio"
    ]
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "R",
    "section": "",
    "text": "R is a programming language with a specific focus on statistical programming. A large part of the original R programming language took inspiration from the S programming language. This is also where it also got its name (R being next to S in the alphabet), together with R being the first name of the developers (Ross Ihaka and Robet Gentleman). R first appeared in August 1993 and the first official R version 1.0 was released on the 29th of February, 2000 (Source).\n\n\n\n\n\n\nStrictly speaking, when we are programming in R, we are not actually programming in R. R is only a language definition, a long set of rules and definitions explaining how R should work. When we code, we actually code in an R implementation: an implementation of the R language definition written in more abstract (read: more computer-friendly, less human-friendly) languages. The R implementation we will be using (and most people use) is written in C, Fortran, and R.",
    "crumbs": [
      "Set-up",
      "R"
    ]
  },
  {
    "objectID": "r.html#r-an-introduction",
    "href": "r.html#r-an-introduction",
    "title": "R",
    "section": "",
    "text": "R is a programming language with a specific focus on statistical programming. A large part of the original R programming language took inspiration from the S programming language. This is also where it also got its name (R being next to S in the alphabet), together with R being the first name of the developers (Ross Ihaka and Robet Gentleman). R first appeared in August 1993 and the first official R version 1.0 was released on the 29th of February, 2000 (Source).\n\n\n\n\n\n\nStrictly speaking, when we are programming in R, we are not actually programming in R. R is only a language definition, a long set of rules and definitions explaining how R should work. When we code, we actually code in an R implementation: an implementation of the R language definition written in more abstract (read: more computer-friendly, less human-friendly) languages. The R implementation we will be using (and most people use) is written in C, Fortran, and R.",
    "crumbs": [
      "Set-up",
      "R"
    ]
  },
  {
    "objectID": "r.html#installing-r",
    "href": "r.html#installing-r",
    "title": "R",
    "section": "Installing R",
    "text": "Installing R\nLet’s start by installing R. R can be used on Windows, Apple, and Linux operating systems. To download R, you can go to https://cran.rstudio.com, where you can choose the download link applicable to your platform.\nAfter R is installed, you can open it and you will see the following screen:\n\n\n\n\n\n\nFigure 1: R graphical user interface\n\n\n\nIn Figure 1, you can see the R console, which allows you write code to subsequently yield results. However, as you might have noticed, the interface is quite limited in the information it shows you. This is why it is a good idea to install an Integrated Development Environment (also called an IDE).",
    "crumbs": [
      "Set-up",
      "R"
    ]
  },
  {
    "objectID": "r.html#next-topic",
    "href": "r.html#next-topic",
    "title": "R",
    "section": "Next topic",
    "text": "Next topic\nNow that we have R, let’s install the RStudio IDE.\nNext: Installing the RStudio IDE",
    "crumbs": [
      "Set-up",
      "R"
    ]
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "Packages",
    "section": "",
    "text": "We now know how we can access our data and manipulate it. However, everything that we saw until now is by default available in R. Nonetheless, we cannot expect the maintainers of R (the R Core Team) to implement every idea, optimalization, and statistical method. This is where packages come in.\nPackages are libraries of functions created by other people implementing certain methods, ideas, and optimalizations. These packages allow us to implement certain methods, perform certain analyses, and improve our code, without having to program this all ourselves.",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#packages",
    "href": "packages.html#packages",
    "title": "Packages",
    "section": "",
    "text": "We now know how we can access our data and manipulate it. However, everything that we saw until now is by default available in R. Nonetheless, we cannot expect the maintainers of R (the R Core Team) to implement every idea, optimalization, and statistical method. This is where packages come in.\nPackages are libraries of functions created by other people implementing certain methods, ideas, and optimalizations. These packages allow us to implement certain methods, perform certain analyses, and improve our code, without having to program this all ourselves.",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#pre-installed-packages",
    "href": "packages.html#pre-installed-packages",
    "title": "Packages",
    "section": "Pre-installed packages",
    "text": "Pre-installed packages\nSome packages come pre-installed with R. For example, sum() comes from the base package, while sd() comes from the stats package. We can see the currently installed packages in RStudio in the lower right window in the tab ‘packages’, as seen in Figure 1. Mind you that in Figure 1, there might be different packages than in your window, depending on what packages are already or not yet installed.\nIn Figure 1, you can see a checkbox, which indicates whether a package is loaded (more on that in a few lines), the package name, a description, a version, and buttons to the homepage, and an option to remove the package.\n\n\n\n\n\n\nFigure 1: Installed packages\n\n\n\nIf we want to check out what a package does, we can ask for help on a package in the same way as we ask for help on a function:\n?stats\nWe could also open an extensive overview of a package’s details using library():\nlibrary(help = \"stats\")\nThis overview shows us not only detailed information on the package, but also the functions the package supplies.\n\n\n\n\n\n\nWhen we talk about packages, for example when asking a question on stack overflow, packages can be denoted with curly brackets. For instance, the base package could be called {base}.",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#installing-packages",
    "href": "packages.html#installing-packages",
    "title": "Packages",
    "section": "Installing packages",
    "text": "Installing packages\nAlthough the pre-installed packages give us a lot of functionality, we might still want more. Yes, with {stats} we can do a linear regression, but not Cox regression. If we want to perform a Cox regression, we could use the {survival} package. To install it, we can use the below code. You might be prompted to pick a mirror for installation, which basically just means: ‘choose a website identical to the original download website, but with a different server’. This way, you can pick a server in your own country increasing download speeds.\ninstall.packages(\"survival\")\n\n\nWhen packages are installed, they will always give the message MD5 sums checked. MD5 is an algorithm that can help identify unintentional data/file corruption (more).\nWhen we install a package, the package is downloaded from the Comprehensive R Archive Network (CRAN), which is the same place where you also downloaded R itself.\n\nR tools\nSometimes you might get an error message when installing a package, which indicates that you need a program called RTools to install the package. To resolve this error, you can install RTools from CRAN.\n\n\nPackage versions\nPackages have two versions: the version of the package and the version of R for which they were build. The package version simply indicates the progress of development of that package, but the version of R for which the package was built is more important. There can be three cases:\n\nThe package is built for your current version of R: there will be no problem.\nThe package is built for a newer version of R: you will receive a warning, but other than that, this will not be a problem.\nThe package is built for an older version of R: you cannot use the package with your current version of R. You can look if there is another package which offers the same functionalities or, less ideally, switch back to an older version of R.\n\n\n\nInstalling from GitHub\nSometimes, packages do not exist on CRAN yet; the package might not be fully ready yet or still be edited frequently. In such a case, you could install a package from GitHub. To do this, first you need to install {devtools}:\ninstall.packages(\"devtools\")\nFrom {devtools}, we can use the install_github() function to install a package. For instance, if we wanted to install {KMunicate} from GitHub, we could run:\ninstall_github(\"ellessenne/KMunicate-package\")\nwhere ellessenne is the GitHub user’s username and KMunicate-package the repository of the package.",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#loading-packages",
    "href": "packages.html#loading-packages",
    "title": "Packages",
    "section": "Loading packages",
    "text": "Loading packages\nThe good thing about installing packages is that we only have to install them once on our device. Once they are installed, at the beginning of your R session, you can load them in using library(). If we wanted to load {survival} after installing it previously, we can do:\nlibrary(\"survival\")\nWe could also load multiple packages at once with library():\nlibrary(\"survival\", \"stats\")\nThe help function for library() shows that there is also a function called require(). In general, this works similar to library() but is used more often within functions. Whereas library() will return an error if the package is not installed, require() will only give a warning.\n\nMasking\nSometimes, we may get the warning that certain functions become masked:\n\n# Here we set the mirror for downloading, but this is only needed for the tutorial to render: in your own R, you do not need to do this.\noptions(repos = c(CRAN = \"https://mirror.lyrahosting.com/CRAN/\"))\n\n# Install dplyr\n# We only use quiet = TRUE here to reduce output shown in the tutorial, you do not need to do this in your own code.\ninstall.packages(\"dplyr\", quiet = TRUE)\n\npackage 'dplyr' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'dplyr'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\rjjanse.LUMCNET\\AppData\\Local\\Programs\\R\\R-4.4.0\\library\\00LOCK\\dplyr\\libs\\x64\\dplyr.dll\nto\nC:\\Users\\rjjanse.LUMCNET\\AppData\\Local\\Programs\\R\\R-4.4.0\\library\\dplyr\\libs\\x64\\dplyr.dll:\nPermission denied\n\n\nWarning: restored 'dplyr'\n\n\n\n# Load dplyr\nlibrary(\"dplyr\")\n\nWarning: package 'dplyr' was built under R version 4.4.1\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nLoading the package {dplyr} caused, among others, the function filter() from {stats} to be masked. This means that if we call filter(), we will call the function from {dplyr}, not from {stats}, which might have a different functionality. If we still want to use filter() from {stats}, we can prespecify the package with a double colon :::\nstats::filter()\n\n\n\n\n\n\nIn general, we can call functions from installed packages without loading the package, by using ::. Without loading {survival}, we can still call survival::coxph(), so long as {survival} is installed.\n\n\n\n\n\nPacman\nIt can be a hassle to first install packages and then load them with library. By using the package {pacman}, we can simplify this process. We only need to install it once on our device and after that we load any package with:\npacman::p_load(\"survival\", \"dplyr\")\n{pacman} will first check if a package is installed. If it is not, the package will first be installed from CRAN and then loaded, otherwise it will just be loaded. By calling the function p_load() immediately from {pacman} with ::, we do not need to load {pacman} first.\nNote that {pacman} does not tell you whether a function becomes masked.\n\n\nAnnotating package loading\nAlthough we might know why we load certain packages, another person reading our code might not. Therefore, it is good practice to annotate for what reason we load certain packages. For example, you can annotate package loading as such:\n# Load packages\npacman::p_load(\"dplyr\",         # Data manipulation\n               \"tidyr\",         # Pivoting data\n               \"magrittr\",      # Efficient pipe structures\n               \"stringr\",       # Better regexing\n               \"mice\",          # Multiple imputation\n               \"summarytools\",  # Summarizing data frames\n               \"haven\"          # Load SPSS data\n)",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#learning-how-to-work-with-packages",
    "href": "packages.html#learning-how-to-work-with-packages",
    "title": "Packages",
    "section": "Learning how to work with packages",
    "text": "Learning how to work with packages\n\nDemos\nPackages can supply demos on how to work with certain functions in the package. To see this for the packages loaded by the base package, we can use demo():\ndemo()\nWe could also see the demos for all packages installed:\ndemo(package = .packages(all.available = TRUE))\n\n\nVignettes\nMore commonly, packages offer vignettes instead of demos. Vignettes are long guides on how to apply a certain concept using different functions in the package. To see the available vignettes of a package, we can use browseVignettes():\nbrowseVignettes(\"survival\")\nWe can also immediately select a vignette of interest:\nvignette(\"splines\")\nTo see the object names to open vignettes from vignette(), we can supply only the package:\nvignette(package = \"survival\")",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#updating-and-unistalling-packages",
    "href": "packages.html#updating-and-unistalling-packages",
    "title": "Packages",
    "section": "Updating and unistalling packages",
    "text": "Updating and unistalling packages\n\nUpdating\nSometimes, an R package might get an update to resolve a mistake or to add an extra feature. If we want to update our R packages, we could so from the list of packages in the package view in RStudio (Figure 1). Alternatively, we can just rerun the package installation using install.packages() to update it. Note that we cannot use {pacman} here, as {pacman} will notice the package is installed already and therefore only load it, not (re)install it. To update packages, we can also use update.packages(), although this might not update packages to a version suitable for new major R versions.\n\n\nUninstalling\nIf we want to get rid of a package, maybe to clean up some space on our device, we can remove it using remove.packages().\n\n\n\n\n\n\nSometimes we want to update a package, but that package needs an updated version of a package such as {rlang}. This package is always running in the background, so we will be asked whether we want to terminate the activate session of R so that {rlang} can be updated too. However, if we agree, the R session will restart and immediately load {rlang} again, as this is a package that is always loaded. Therefore, to update packages when they need an updated version of {rlang} (or similar cases), first we need to use remove.packages() to uninstall {rlang}, then reinstall {rlang}, and then update the package we wanted to update originally.",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#a-warning",
    "href": "packages.html#a-warning",
    "title": "Packages",
    "section": "A warning",
    "text": "A warning\nAlthough packages are a great way of avoiding writing all kinds of code ourselves, they do not come without their warnings.\n\nDependencies\nAlmost all R packages are built using another R package. This is why installing {dplyr} actually installs a lot of other packages, which are all required to allow {dplyr} to function. These are called dependencies. Because packages are dependent on other packages, deprecation of one package might lead to another package not working anymore. Although this is not likely to happen with commonly used packages such as {dplyr}, sometimes this might still cause a package we want to use not to work anymore (or the package we want to use itself is deprecated). Dependencies can become dangerous quickly, as talked about shortly here and here.\n\n\nDeprecate: to withdraw official support for or discourage the use of (something, such as a software product) in favor of a newer or better alternative. Link.\n\n\nTrust\nAnyone can write packages for R, including you and me. On the one hand, this means that everyone can contribute their code to the ease of all other R users. However, this also means that individuals with malicious intent can create R packages. Therefore, you should always be careful when installing R packages. Although CRAN is an archive with many trusted packages, it is not a protection against malicious packages or a guarantee of safety. More on this can be read here.",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#exercises",
    "href": "packages.html#exercises",
    "title": "Packages",
    "section": "Exercises",
    "text": "Exercises\n\n1. Installing a new package\nInstall the package {tidyverse}.\n\n\nAnswer\n# Answer 1: using {pacman}\npacman::p_load(\"tidyverse\")\n\n\nalso installing the dependencies 'ps', 'processx', 'blob', 'gargle', 'uuid', 'ids', 'rematch2', 'timechange', 'systemfonts', 'textshaping', 'callr', 'selectr', 'conflicted', 'dbplyr', 'dtplyr', 'googledrive', 'googlesheets4', 'lubridate', 'modelr', 'ragg', 'reprex', 'rvest', 'xml2'\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.4/PACKAGES'\n\n\n\n  There are binary versions available but the source versions are later:\n     binary source needs_compilation\nps    1.7.7  1.8.0              TRUE\nragg  1.3.2  1.3.3              TRUE\n\npackage 'processx' successfully unpacked and MD5 sums checked\npackage 'blob' successfully unpacked and MD5 sums checked\npackage 'gargle' successfully unpacked and MD5 sums checked\npackage 'uuid' successfully unpacked and MD5 sums checked\npackage 'ids' successfully unpacked and MD5 sums checked\npackage 'rematch2' successfully unpacked and MD5 sums checked\npackage 'timechange' successfully unpacked and MD5 sums checked\npackage 'systemfonts' successfully unpacked and MD5 sums checked\npackage 'textshaping' successfully unpacked and MD5 sums checked\npackage 'callr' successfully unpacked and MD5 sums checked\npackage 'selectr' successfully unpacked and MD5 sums checked\npackage 'conflicted' successfully unpacked and MD5 sums checked\npackage 'dbplyr' successfully unpacked and MD5 sums checked\npackage 'dtplyr' successfully unpacked and MD5 sums checked\npackage 'googledrive' successfully unpacked and MD5 sums checked\npackage 'googlesheets4' successfully unpacked and MD5 sums checked\npackage 'lubridate' successfully unpacked and MD5 sums checked\npackage 'modelr' successfully unpacked and MD5 sums checked\npackage 'reprex' successfully unpacked and MD5 sums checked\npackage 'rvest' successfully unpacked and MD5 sums checked\npackage 'xml2' successfully unpacked and MD5 sums checked\npackage 'tidyverse' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\rjjanse.LUMCNET\\AppData\\Local\\Temp\\RtmpsvjtpR\\downloaded_packages\n\n\ninstalling the source packages 'ps', 'ragg'\n\n\n\ntidyverse installed\n\n\nWarning: package 'tidyverse' was built under R version 4.4.1\n\n\nWarning: package 'ggplot2' was built under R version 4.4.1\n\n\nWarning: package 'tibble' was built under R version 4.4.1\n\n\nWarning: package 'tidyr' was built under R version 4.4.1\n\n\nWarning: package 'readr' was built under R version 4.4.1\n\n\nWarning: package 'purrr' was built under R version 4.4.1\n\n\nWarning: package 'stringr' was built under R version 4.4.1\n\n\nWarning: package 'forcats' was built under R version 4.4.1\n\n\nWarning: package 'lubridate' was built under R version 4.4.1\n\n\nAnswer\n# Answer 2: using install.packages()\n# We only use quiet = TRUE here to reduce output shown in the tutorial, you do not need to do this in your own code.\ninstall.packages(\"tidyverse\", quiet = TRUE)\n\n\nWarning: package 'tidyverse' is in use and will not be installed\n\n\n\n\n2. Loading a new package\nNow load the package {tidyverse}\n\n\nAnswer\n# Answer 1: using {pacman}, the package is already loaded after installing\n\n# Answer 2: using library() after install.packages()\nlibrary(\"tidyverse\")",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "packages.html#next-topic",
    "href": "packages.html#next-topic",
    "title": "Packages",
    "section": "Next topic",
    "text": "Next topic\nNow that we know the basics of R packages, let’s start looking at how we can harness their power to load our own data.\nNext: Data",
    "crumbs": [
      "The basics",
      "Packages"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "Hi and welcome to this R tutorial! This tutorial aims to teach you the basics of R (and RStudio), but also take you further, showing you different alternatives to reach the same goal and learning some useful tricks to quickly become an efficient R user. The general focus is on using R for epidemiologic data analysis, such as how to perform regression analyses and plot results, although it also contains a comprehensive introduction to R.\nThroughout the tutorial, there will be example code. Feel free to also write and run this on your own device and play around with changing things up to see what happens.\nAdditionally, there will be exercises you can make to keep track of your learning progress. Answers to the exercises are available under the ‘Answer’ button. An example is shown below.\nThis tutorial might feel rather dense and time-consuming as compared to other tutorials but you do not have to do everything at once. Although it is a good idea to do the basics and learn about the tidyverse, other sections might be studied on a need-to-know basis. Additionally, this tutorial will (hopefully) leave you with knowledge about using R, but also hand you the tools to learn more yourself and quickly understand new concepts and functions.\n\nExercises\n0: Open the answer\n\n\nAnswer\n# Well done!\n\n\nNext: R",
    "crumbs": [
      "Start",
      "Introduction"
    ]
  },
  {
    "objectID": "creating.html",
    "href": "creating.html",
    "title": "Creating data",
    "section": "",
    "text": "Let’s get started in R. Before we write any code, we should discuss the importance of annotation. When you are writing code it might seem clear to you what each line does, but if someone else reads your code or you look back at your code after a while, it might not seem so clear anymore. To allow others and your future-self to efficiently check, read, and re-use your code, it is important to extensively annotate your code. Let’s see some unannotated code (you don’t have to understand now what the code means):\niris %&gt;%\n    filter(Species == \"setosa\") %&gt;%\n    extract2(\"Sepal.Length\") %&gt;%\n    is_greater_than(5) %&gt;%\n    table() %&gt;%\n    prop.table() %&gt;%\n    extract2(TRUE) %&gt;%\n    `*`(100) %&gt;%\n    paste0(., \"%\")\nIn this section of code, there is a lot that happens (although some R users might still get the gist of the code). Moreover, a single section of code might quickly get much longer and more complicated than the above example. Luckily, the code can added to with annotation. In R, you can annotate with ‘#’. Any text written after the ‘#’ on the same line will not be run by R and can therefore be used to annotate code. So let’s see how we can increase this code’s clarity with annotation:\n# Calculate proportion of setosa observations with sepal length above 5\niris %&gt;%\n    # Keep only setosa species\n    filter(Species == \"setosa\") %&gt;%\n    # Keep only the sepal length values\n    extract2(\"Sepal.Length\") %&gt;%\n    # Determine whether each value is greater than 5 or not\n    is_greater_than(5) %&gt;%\n    # Count lengths above and below 5\n    table() %&gt;%\n    # Turn counts into proportions\n    prop.table() %&gt;%\n    # Keep only proportion for lengths above 5\n    extract2(TRUE) %&gt;%\n    # Multiply by 100\n    `*`(100) %&gt;%\n    # Add percentage sign\n    paste0(., \"%\")\nIt is true that annotation increases the length of a script, but it is important to note that the quality of a script is not affected by its length, but it is by its clarity.\n\n\n\n\n\n\nYou can use annotation for more than just explaining what your code does. You can add information on the general purpose of a script, its author, its creation date. You can add information on why you made a certain decision or add a URL to where you found the solution to a coding problem. It is easy to annotate too little, but difficult to annotate too much.",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#annotation",
    "href": "creating.html#annotation",
    "title": "Creating data",
    "section": "",
    "text": "Let’s get started in R. Before we write any code, we should discuss the importance of annotation. When you are writing code it might seem clear to you what each line does, but if someone else reads your code or you look back at your code after a while, it might not seem so clear anymore. To allow others and your future-self to efficiently check, read, and re-use your code, it is important to extensively annotate your code. Let’s see some unannotated code (you don’t have to understand now what the code means):\niris %&gt;%\n    filter(Species == \"setosa\") %&gt;%\n    extract2(\"Sepal.Length\") %&gt;%\n    is_greater_than(5) %&gt;%\n    table() %&gt;%\n    prop.table() %&gt;%\n    extract2(TRUE) %&gt;%\n    `*`(100) %&gt;%\n    paste0(., \"%\")\nIn this section of code, there is a lot that happens (although some R users might still get the gist of the code). Moreover, a single section of code might quickly get much longer and more complicated than the above example. Luckily, the code can added to with annotation. In R, you can annotate with ‘#’. Any text written after the ‘#’ on the same line will not be run by R and can therefore be used to annotate code. So let’s see how we can increase this code’s clarity with annotation:\n# Calculate proportion of setosa observations with sepal length above 5\niris %&gt;%\n    # Keep only setosa species\n    filter(Species == \"setosa\") %&gt;%\n    # Keep only the sepal length values\n    extract2(\"Sepal.Length\") %&gt;%\n    # Determine whether each value is greater than 5 or not\n    is_greater_than(5) %&gt;%\n    # Count lengths above and below 5\n    table() %&gt;%\n    # Turn counts into proportions\n    prop.table() %&gt;%\n    # Keep only proportion for lengths above 5\n    extract2(TRUE) %&gt;%\n    # Multiply by 100\n    `*`(100) %&gt;%\n    # Add percentage sign\n    paste0(., \"%\")\nIt is true that annotation increases the length of a script, but it is important to note that the quality of a script is not affected by its length, but it is by its clarity.\n\n\n\n\n\n\nYou can use annotation for more than just explaining what your code does. You can add information on the general purpose of a script, its author, its creation date. You can add information on why you made a certain decision or add a URL to where you found the solution to a coding problem. It is easy to annotate too little, but difficult to annotate too much.",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#basic-mathematic-operators-and-running-code",
    "href": "creating.html#basic-mathematic-operators-and-running-code",
    "title": "Creating data",
    "section": "Basic mathematic operators and running code",
    "text": "Basic mathematic operators and running code\nNow let’s (finally) see some real code! Let’s start with some basic operators:\n1 + 1   # Addition\n3 - 1   # Substraction\n2 * 3   # Multiplication\n8 / 2   # Division\n8 %% 2  # Modulo\nR follows the conventional order of mathematic operation.\nHowever, these operators are useless if we do not actually run the code. To run a section of code, put your cursor in the code section (can be anywhere) and press ctrl + enter to run the code. If you want to run a specific part of the code, instead of a whole section, you can select the part you want to run and then use ctrl + enter again, to run only the selected part.\nThe results of the selected code can be found in the console. If the code takes some time to run, you can see it is done when a new line of the console starts with &gt; (Figure 1 (a)).\n\n\n\n\n\n\nIf you select a specific part of code to run, make sure to be inclusive! For instance, if you forget to select an enclosing paranthesis, the selected code will be put in the console, but it will not be run. You can see that this happened if a new line in the console starts with + (Figure 1 (b)). To cancel a waiting command, you can press esc.\n\n\n\nIf we run the example code for the basic mathematic operators, we will get the following results:\n\n1 + 1   # Addition\n\n[1] 2\n\n3 - 1   # Substraction\n\n[1] 2\n\n2 * 3   # Multiplication\n\n[1] 6\n\n8 / 2   # Division\n\n[1] 4\n\n8 %% 2  # Modulo\n\n[1] 0\n\n\nBefore each result, you can see [1]. This indicates that that specific line of code starts with the nth result. When a single code starts printing multiple results, this can help identify what n a certain result is.\n\n\n\n\n\n\n\n\n\n\n\n(a) Ready\n\n\n\n\n\n\n\n\n\n\n\n(b) Waiting for input to finish\n\n\n\n\n\n\n\nFigure 1: Console states",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#functions",
    "href": "creating.html#functions",
    "title": "Creating data",
    "section": "Functions",
    "text": "Functions\nNow that we know the basic mathematic operators, we could calculate the standard deviation. For example, for the numbers 3, 8, 3, 7 and 1, we could do the following:\n\n# Calculate the mean\n(3 + 8 + 3 + 7 + 1) / 5\n\n[1] 4.4\n\n\n\n# Use the calculated mean to calculate the standard deviation\n(((3 - 4.4) ^ 2 + (8 - 4.4) ^ 2 + (3 - 4.4) ^ 2 + (7 - 4.4) ^ 2 + (1 - 4.4) ^ 2) / (5 - 1)) ^ 0.5\n\n[1] 2.966479\n\n\n\n\nA sample’s standard deviation \\(s\\) is obtained by calculating:\n\\[\\sqrt\\frac{\\sum{(x-\\overline{x})^2}}{n-1}\\]\nHowever, with only 5 numbers, this is already a lot of effort. This is where functions come in: R has many built-in keywords that allow you to quickly perform operations and/or calculations on the data, which we call functions. A function has a generic name and is followed by opening and closing brackets. Between the brackets, we can supply so-called arguments (i.e., data and/or specifications). For example, if we wanted to calculate the standard deviation, instead of typing out all the numbers, we could just type the following:\n\n# Calculate standard deviation\nsd(c(3, 8, 3, 7, 1))\n\n[1] 2.966479\n\n\n\n\n\n\n\n\nIn the standard deviation function, we use the c() function. Later we will elaborate on this, but for now it is enough to remember that c() creates a collection of data, which is more often called an object.\nBe aware that R is case-sensitive: c() as a function differs from C().\n\n\n\nLet’s see some standard functions that will be of great help to you.\n\nSum\nsum(), as it name suggests, sums the supplied values. It has the following arguments:\n\n...: the ellipsis indicates that any number of values can be supplied here. The sum function can take numeric values, integers, and booleans/logicals (i.e., it can sum the amount of TRUEs).\nna.rm = FALSE: na.rm indicates whether any missing values should be dropped. By default, this is FALSE, meaning that the function will return NA if there is any NAs present in the data you are trying to sum. If you want to sum all valid values (thus drop all NAs), you can specify na.rm = TRUE.\n\nSee the below examples:\n\nsum(3, 4, 5, 6)\n\n[1] 18\n\nsum(3, NA, 5, 6)\n\n[1] NA\n\nsum(3, NA, 5, 6, na.rm = TRUE)\n\n[1] 14\n\n\n\n\n\n\n\n\nIn the sum() function, na.rm has the default value FALSE. This means that this argument does not have to be defined. If we would not define it, it would just use FALSE.\n\n\n\n\n\nMean and median\nTo get the mean or median from some data, you can use the mean() and median() functions. mean() has the following arguments:\n\nx: a collection (or object) of data containing the data for which a mean should be calculated.\ntrim = 0: what proportion of the outskirts of the data should be trimmed (e.g., 0.05 trims 5% of data on each side). It defaults to 0.\nna.rm = FALSE: whether NAs should be dropped (as in sum())\n\nmedian() has the same arguments, except that it doesn’t have trim.\nHere are some examples:\n\nmean(c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044))\n\n[1] 98.63636\n\nmean(c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044), trim = 0.1)\n\n[1] 4.555556\n\nmedian(c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044))\n\n[1] 4\n\n\n\n\n\n\n\n\nNotice how with the mean, we specified that 0.1 was the value for trim, but we did not specify that c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044) was the value for x. This is because R inputs values for arguments in order: the first supplied value will be used for the first argument, the second supplied value will be used for the second argument, etc. However, sometimes I do not want to specify the second value, but I do want to specify the third value. In this case I can name the argument as in trim = 0.1, so that R knows the 0.1 is meant for trim.\n\n\n\n\n\nMin and max\nNow that we know how to calculate the mean and median from some data, we might also be interest in finding the lowest and highest value (for example, to detect the 1044 outlier). We can do this with min() and max(), which both take only one argument: ... as in the sum() function.\nTo get the minimum and maximum value from the data we just calculated the mean and median of, we could do the following:\n\nmin(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044)\n\n[1] 0\n\nmax(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044)\n\n[1] 1044\n\n\n\n\nSummary and quintile\nNow we know how to calculate the mean, median, minimum, and maximum values from some data, but what if we also want to know the 1st and 3rd quartile? Additionally, we do not want to use a function for each separate value. In this case, you can use summary(), which calculates the minimum, 1st quartile, mean, median, 3rd quartile, and maximum all at once. The summary function has multiple arguments, but only one is relevant for now:\n\nobject: the data of which you want to get a summary.\n\nFor example:\n\nsummary(c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    3.00    4.00   98.64    7.50 1044.00 \n\n\nHowever, maybe we are more interested in the 1st and 99th quantiles. In that case we could use quantile(). You can supply the following arguments to quantile():\n\nx: a collection of data (or object) of which you want to calculate quantiles.\nprobs = seq(0, 1, 0.25): the probabilities (or quantiles) you want to calculate. It defaults to seq(0, 1, 0.25), which just means a sequence from 0 to 1 with increments of 0.25.\nna.rm = FALSE: whether NAs should be dropped.\nnames = TRUE: whether the output should show the name (or specified quantile).\n\nSo we could do:\n\nquantile(c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044), \n         probs = c(0.01, 0.99))\n\n   1%   99% \n  0.1 940.4 \n\nquantile(c(3, 4, 8, 3, 0, 4, 7, 8, 3, 1, 1044), \n         probs = c(0.01, 0.99), names = FALSE)\n\n[1]   0.1 940.4\n\n\n\n\nTable\nWe have now seen some functions that we can use to get some descriptives about continuous data. However, sometimes we just want to count the amount of different observations. For this we can use table(). Some of the relevant arguments for the table function are the following:\n\n...: the variables to be supplied to table, as we saw in earlier functions.\nuseNA = c(\"no\", \"ifany\", \"always\"): should NAs be tabulated (conditional on if any are present) or not. The c(\"no\", \"ifany\", \"always\"), means that useNA takes any of the three following values: \"no\", \"ifany\", or \"always\".\n\nFor example:\n\ntable(c(TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, NA))\n\n\nFALSE  TRUE \n    3     5 \n\ntable(c(TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, NA), \n      useNA = \"ifany\")\n\n\nFALSE  TRUE  &lt;NA&gt; \n    3     5     1 \n\ntable(c(TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE), \n      useNA = \"always\")\n\n\nFALSE  TRUE  &lt;NA&gt; \n    3     5     0 \n\n\nYou can also use table() to create a cross-table:\n\ntable(c(FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE), \n      c(TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE))\n\n       \n        FALSE TRUE\n  FALSE     3    1\n  TRUE      3    2\n\n\nFor the cross-tabulation, values are compered based on their order in the data you supply (e.g., the first value, FALSE in the first set is compared to the first value, TRUE, in the second set.)\n\n\n\n\n\n\nWe now went through some arguments for commonly used functions together, but it is good that you know what arguments a function takes and where you can find this. If you want to know more about any function, for example for sum(), you can open the documentation by running ?sum. In the help panel on the lower right in RStudio, you will find the documentation with the function, its default values, elaboration on the arguments it takes, details, and examples. You can also click on a function and press F1 to open the help panel.",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#storing-values",
    "href": "creating.html#storing-values",
    "title": "Creating data",
    "section": "Storing values",
    "text": "Storing values\nWe have now seen how we can calculate some values using basic mathematic operators and functions. However, just typing out our data can become quite tiresome, so preferably I would store them in a variable. In R, things that store data are often called subjects. Let’s look at some different ways we can store data.\n\nSingle value\nWe can assign a single value by using the &lt;- operator (which has the easy keyboard shortcut alt + - in RStudio). To then see the object, we can simply run it. For example:\n\nx &lt;- sum(4, 9)\nx\n\n[1] 13\n\nx &lt;- 4 + 5\nx\n\n[1] 9\n\n\n\n\n\n\n\n\nNote that we defined the object x twice. When defining an object that already exists, the old object is overridden.\n\n\n\n\n\n\n\n\n\nTo assign a value to an object, you can also use = instead of &lt;-. However, this is often unclear and may be confused with defining arguments in functions. It is therefore strongly recommended to only assign objects using &lt;-.\n\n\n\n\n\nVectors\nWhen we want to assign multiple values to a single variable, we can create a vector. There are two simple ways to create a vector. First, we can use the c function (c()), that we saw before when discussing functions. c() creates a simple collection of any type of value. We call this collection a vector.\n\nx &lt;- c(4, 6, 9, 3, 2)\nx\n\n[1] 4 6 9 3 2\n\n# Using a vector in the sum function\nsum(x)\n\n[1] 24\n\n\nYou can also create a vector of sequential integers by using ::\n\nx &lt;- 5:17\nx\n\n [1]  5  6  7  8  9 10 11 12 13 14 15 16 17\n\n\nAdditionally, you can create any sequence using the seq() function which takes the arguments from, to, and by, meaning respectively the start, finish, and increments of the sequence.\n\nx &lt;- seq(5, 7, 0.5)\nx\n\n[1] 5.0 5.5 6.0 6.5 7.0\n\n\nWe could also multiply two vectors with each other (given they have the same length) or a vector with a single value:\n\nx &lt;- 1:5\ny &lt;- 5:1\n\nx * y\n\n[1] 5 8 9 8 5\n\nx * 2\n\n[1]  2  4  6  8 10\n\n\nLastly, you could create a named vector (i.e., each value has a name):\n\nx &lt;- c(\"Obs1\" = 42, \"Obs2\" = 28, \"Obs3\" = 91)\nx\n\nObs1 Obs2 Obs3 \n  42   28   91 \n\n\n\n\nLists\nA list is also a collection of data, but it can store much more than just values, such as vectors, and whole data sets:\n\nx &lt;- list(head(iris, 3), head(mtcars, 3))\nx\n\n[[1]]\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\n[[2]]\n               mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n\n\nHowever, you cannot immediately apply mathematic operators on a list or use a list in data. If we have a list with data (for example different objects), we first have to unlist:\n\nx &lt;- list(4, 2)\nunlist(x) * 2\n\n[1] 8 4\n\n\nWhen you create a model, they are always stored in lists too, with many information alongside the results. We will come across this later in the tutorial.\n\n\nMatrices\nIf we want data with more than one dimension (i.e., columns and rows), we could create a matrix with the matrix function:\n\nx &lt;- matrix(c(31, 3, 18, 7, 84, 20), nrow = 3, ncol = 2)\nx\n\n     [,1] [,2]\n[1,]   31    7\n[2,]    3   84\n[3,]   18   20\n\n\nWe can also supply a single value that fills the entire matrix:\n\nx &lt;- matrix(\"Hello, World!\", nrow = 5, ncol = 3)\nx\n\n     [,1]            [,2]            [,3]           \n[1,] \"Hello, World!\" \"Hello, World!\" \"Hello, World!\"\n[2,] \"Hello, World!\" \"Hello, World!\" \"Hello, World!\"\n[3,] \"Hello, World!\" \"Hello, World!\" \"Hello, World!\"\n[4,] \"Hello, World!\" \"Hello, World!\" \"Hello, World!\"\n[5,] \"Hello, World!\" \"Hello, World!\" \"Hello, World!\"\n\n\nMatrices are useful because they have multiple dimensions, which allows us to store different variables of the same person in multiple columns along the same row.\n\n\nData frames\nMatrices give us a flexible way to store data with rows and columns, but miss some flexibility when it comes to manipulating the data and performing calculations, loading it into functions, etc. In this case, data frames offer a good solution. Data frames look exactly matrices, but are much easier to manipulate and use for analyses. Data frames are likely what will compose most of the data you use in R.\nWe can create a data frame with the data.frame() function:\n\nx &lt;- data.frame(id = 1:5,\n                value1 = c(5, 2, 0, 2, 4),\n                value2 = c(9.4, 8.3, 2.8, 5.6, 2.7))\nx\n\n  id value1 value2\n1  1      5    9.4\n2  2      2    8.3\n3  3      0    2.8\n4  4      2    5.6\n5  5      4    2.7\n\n\nWhen working with data frames, there are some useful functions you can use:\n\nTo determine how many rows and columns a data frame (or matrix) has, you can use nrow() and ncol().\nTo change the row and column names, you can use rownames() and colnames(). To see how these functions work, you can access the examples in their documentation with ?rownames and ?colnames.\nTo change a data frame to a matrix or a matrix to a data frame, you can use as.matrix() and as.data.frame().",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#the-global-environment",
    "href": "creating.html#the-global-environment",
    "title": "Creating data",
    "section": "The global environment",
    "text": "The global environment\nWe have seen some ways to create and store data now. However, where can we find back what we have created? This is where the global environment comes in. Whenever you create an object in your code, that object will be stored in the global environment, which is just a general storage space. A great benefit that RStudio gives us is being able to see the global environment and whatever is stored in there, and to get a quick indication of what kind of data is stored.\nBefore we see the global environment, let’s first clean it with the following code:\nrm(list = ls())\nWith the rm() function, we can remove objects from our global environment, and here we specify that the list of variables to be removed (list =), is the whole global environment (ls()). It is useful to remove objects you do not need to keep your global environment clean. Not only does it help in available working memory, it is also good to work in an organized (global) environment.\nNow let’s create some new data to showcase the global environment in RStudio:\n# Load pre-existing data frame\ndata &lt;- iris\n\n# Create vector\nvector &lt;- 1:13\n\n# Create single value\nval &lt;- 42\n\n# Create vector of strings\nstrings &lt;- c(\"Hello\", \"I\", \"am\", \"a\", \"vector\")\nNow let’s look at our global environment. If you remember, the upper right window of the RStudio interface shows the global environment. With the data we just created, it will look like Figure 2 (a) (the colours might differ depending on your theme).\nFrom the global environment, we can learn a few things:\n\nThe current memory usage is 121 MiB, in the upper middle of the image.\nWe have one structured data object, data. This data object has 150 observations (rows) of 5 variables (columns).\nstrings is a character (chr) with 5 values ([1:5). We then see the first values.\nval is a single value, 42.\nvector is an integener (int) with 13 values ([1:13]`) and we can see the first values.\n\nThis already gives us quite some information, but we can also get some more information on the structured data. If you press the small blue button with an arrow, next to data, you will see that it opens, as in Figure 2 (b). This let’s us learn the following information about data:\n\nWe can see each of the columns of data. The first four are numerical (num).\nThe fifth column, Species, is a factor (i.e., categorical) with three levels (of which the first one is “setosa”).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Global environment\n\n\n\n\n\n\n\n\n\n\n\n(b) Global environment with opened data\n\n\n\n\n\n\n\nFigure 2: The global environment",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#dealing-with-warnings-and-errors",
    "href": "creating.html#dealing-with-warnings-and-errors",
    "title": "Creating data",
    "section": "Dealing with warnings and errors",
    "text": "Dealing with warnings and errors\nWe have now gone through the basics of creating and storing data. However, sometimes, we supply a wrong value to a function or mess up a parenthesis somewhere. This can give either warnings or errors. In both cases, it is important to realize what is happening. Warnings are messages printed in the console that try to tell us that something might be wrong in the data or not suited, or that the data was manipulated in the function to make sure the function could work. For example, if I try to change a character string to numeric with as.numeric(), I will get the warning: Warning message: NAs introduced by coercion, but the function still completed.\nSometimes, warnings are expected or not a problem. In that case, you can put the whole code inside the function supressWarnings(), to silence the warning. It is however always of paramount importance that you annotate what the warning was and why it can be suppressed.\nSometimes, you might get an error instead of a warning. This means that the function could not continue to run and you have to fix the error before being able to run the function.\nNot all errors are as clear and you can not always figure out by yourself what is going wrong. Luckily, we have the internet! You can easily google the error and add ‘R’ at the end to find other people who encountered the same or similar problems and find solutions. If you can find nothing, you could always ask on coding forums, such as stackoverflow. When you ask a solution to a coding question, always supply your question with a reproducible example, so that a responder can run the code themselves and see where it goes wrong.",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#exercises",
    "href": "creating.html#exercises",
    "title": "Creating data",
    "section": "Exercises",
    "text": "Exercises\n\n1. Create and store numbers\nCreate a vector of the integers 5, 6, 7, 8, 9, and 10 and store it in an object called vec.\n\n\nAnswer\n# Answer 1: using c()\nvec &lt;- c(5, 6, 7, 8, 9, 10)\n\n# Answer 2: using the `:` operator\nvec &lt;- 5:10\n\n# Answer 3: using seq()\nvev &lt;- seq(5, 10, 1)\n\n\n\n\n2. Calculate quantiles\nCalculate the 2.5th and 97.5th percentile of the object vec.\n\n\nAnswer\nquantile(vec, probs = c(0.025, 0.975))\n\n\n 2.5% 97.5% \n5.125 9.875 \n\n\n\n\n3. Create a matrix\nUsing the data in vec, create a matrix with two columns and three rows.\n\n\nAnswer\nmatrix(vec, nrow = 3, ncol = 2)\n\n\n     [,1] [,2]\n[1,]    5    8\n[2,]    6    9\n[3,]    7   10\n\n\n\n\n4. Getting help\nOpen the documentation for rm().\n\n\nAnswer\n?rm\n\n\n\n\n5. Cleaning up\nNow use rm() to remove vec again.\n\n\nAnswer\nrm(vec)",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "creating.html#next-topic",
    "href": "creating.html#next-topic",
    "title": "Creating data",
    "section": "Next topic",
    "text": "Next topic\nNow that we went through the basics of creating and storing data, we can start talking about accessing and manipulating data.\nNext: Using data",
    "crumbs": [
      "The basics",
      "Creating data"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "External data",
    "section": "",
    "text": "We have already seen how to create data from scratch, but it is more likely that your data is not created that way. Instead, most data is stored in electronic data capture systems. These systems can then return files which allow the data to be read into statistical programs. This data may come in multiple formats and here we will discuss how to read these different formats into your R Global Environment.",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#why-we-need-to-load-data",
    "href": "data.html#why-we-need-to-load-data",
    "title": "External data",
    "section": "",
    "text": "We have already seen how to create data from scratch, but it is more likely that your data is not created that way. Instead, most data is stored in electronic data capture systems. These systems can then return files which allow the data to be read into statistical programs. This data may come in multiple formats and here we will discuss how to read these different formats into your R Global Environment.",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#the-basics",
    "href": "data.html#the-basics",
    "title": "External data",
    "section": "The basics",
    "text": "The basics\n\nWorking directionary\nWhen we want to load into our Global Environment, by default R will look in a certain spot in our device: the working directionary. By default, the working directionary is the same spot where our R script is saved. The path to the working directionary can be found by using getwd(). If we want to specify a different workign directionary, for instance because our data is in a folder separate from our codes, we can use setwd(), specifying the path to the directionary.\n\n\nFile\nAll methods of reading data require an argument file (sometimes called path or data_file), which ?base::load() defines as a (readable binary-mode) connection or a character string giving the name of the file to load (when tilde expansion is done). This file is simply a path to the document we want to load in. For example: C:/users/username/documents/rtutorial/data/definitely_real_data.csv. Note that the file argument must always end in the file name (definitely_real_data) including extension (.csv).\n\n\nTilde expansion\nRemembering where all your data is stored and writing it all out (C:/users/username/...) can cost quite some effort. Luckily, we have a concept called tilde expansion. When we set our working directionary with setwd(), we can stop specifying that part in the file argument and instead only specify a tilde (~). Instead of calling C:/users/username/documents/rtutorial, we can set our working directionary to the documents folder:\nsetwd(\"C:/users/username/documents/rtutorial\")\nSubsequently, we can specify any file argument as ~/data/definitely_real_data.csv.",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#delimited-data-with-base-and-readr",
    "href": "data.html#delimited-data-with-base-and-readr",
    "title": "External data",
    "section": "Delimited data with {base} and {readr}",
    "text": "Delimited data with {base} and {readr}\nData is often shared in a .csv format, which stands for Comma Separated Values. If we were to open this file in a normal text editor, we would see that each column of a row is separated by a comma between the values. This is a form of delimited data, where there is a certain character (comma, semicolon, tab) that allows the computer to discern between columns. To read such data, we can use different functions from {base}:\n\nread.csv() allows the reading in of data separated with commas where decimal markers are dots\nread.csv2() allows the reading in of data separated with semicolons where decimal markers are commas\nread.delim() allows the reading in of data separated with tabs where decimal markers are dots\nread.delim2() allows the reading in of data separated with tabs where decimal markers are commas\n\nThese functions only differ in the defaults: if you specify arguments such as sep and dec, they can perform the same actions. When using these functions, the data will be read into R, and we can immediately load it into an object which will create a data frame:\n# Load data\ndat &lt;- read.csv(\"~/data/definitely_real_data.csv\")\nA great alternative to the {base} functions are the functions from {readr}, which are in general faster and treat the data better. The functions have similar names and functionality:\n\nread_csv() allows the reading in of data separated with commas where decimal markers are dots\nread_csv2() allows the reading in of data separated with semicolons where decimal markers are commas\nread_tsv() allows the reading in of data separated with tabs\n\nIf you want to write these data back into a delimited file, we can use the write functions with similar names, besides replacing read with write:\n\nwrite.csv() allows the writing of data separated with commas where decimal markers are dots\nwrite_csv() allows the writing of data separated with commas where decimal markers are dots (but faster than write.csv())\netc.\n\nIn the writing functions, we first specify the object we want to write to our device and then the path:\nwrite_csv(iris, \"~/data/iris.csv\")",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#excel-files",
    "href": "data.html#excel-files",
    "title": "External data",
    "section": "Excel files",
    "text": "Excel files\nIf the data is not supplied in a delimited format, but Excel (.xlsx/.xls), we can use the {readxl} package to read in the data:\n# Load first sheet of Excel file\ndat &lt;- read_excel(\"~/data/definitely_real_data.xlsx\")\n\n# Load third sheet of Excel file\ndat &lt;- read_excel(\"~/data/definitely_real_data.xlsx\", sheet = 3)\n\n# Load Excel file's sheet by name\ndat &lt;- read_excel(\"~/data/definitely_real_data.xlsx\", sheet = \"definitely_real_sheet\")\nUsing the function read_excel() automatically determines whether the data is stored in .xlsx or .xls and therefore whether it should use read_xlsx() or read_xls().\nIf we then want to write data back to Excel, we can use the {writexl} package:\nwrite_xlsx(iris, \"~/data/iris.xlsx\")",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#spss-sas-and-stata-data",
    "href": "data.html#spss-sas-and-stata-data",
    "title": "External data",
    "section": "SPSS, SAS, and Stata data",
    "text": "SPSS, SAS, and Stata data\nIf the data are already formatted for other statistical software, specifically SPSS (.sav, .zsav, and .por), SAS (.sas7bdat) or Stata (.dta, .xpt), we can use {haven} to read these data:\n\nread_spss() can read SPSS files and automatically detects whether a file is .sav/.zsav or .por to use the correct alternative (read_sav() or read_por()).\nwrite_sav() creates an SPSS .sav file (or .zsav if compress = TRUE).\nread_sas() reads in SAS .sas7bdat files.\nread_xpt()reads in SAS transport .xpt files.\nwrite_sas() is a deprecated function and does not perform reliabily. An alternative is the write_xpt() function to write an R object to a SAS transport (.xpt) file.\nread_dta() allows reading of Stata .dta files.\nwrite_dta() writes an R object to a Stata .dta file.",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#foreign",
    "href": "data.html#foreign",
    "title": "External data",
    "section": "Foreign",
    "text": "Foreign\nIf we have data that cannot be loaded in with any of the above functions, we can always have a look whether {foreign} has any functions that can read in the data. {foreign} offers functions for the reading of files such as .ssd, .dbf, .arff, .epiinfo, and more.",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#making-your-life-easier",
    "href": "data.html#making-your-life-easier",
    "title": "External data",
    "section": "Making your life easier",
    "text": "Making your life easier\n\nPoint-and-click import\nOf course it’s nice that all these functions exist to read in your data, but they do not let us preview what the data is going to look like. If we want to preview the data before reading it, in RStudio, we can go to the menu bar, click File and then Import Dataset (Figure 1):\n\n\n\n\n\n\nFigure 1: Import data\n\n\n\nFrom there, we can choose the type of data to import (e.g., Excel) and we will be presented with a viewer (Figure 2). In the upper right corner of the viewer, we can select our data with ‘Browse’, which then shows how the data will look like after import. In the lower left corner, we can adjust some options. Lastly, in the lower right corner, we see the code that will be run to read this data into our Global Enviroment. Once happy with how the data will look upon import, we can press ‘Import’ and the data will be imported. You can then copy the code from the console to add it to your script so that you do not need to repeat this step again.\n\n\n\n\n\n\nFigure 2: Preview of import\n\n\n\n\n\nRio\nIf we do not want to think about what function to use at all, we can use the R Input/Output package {rio}, which provides the functions import() and export(). These functions automatically recognize the format of the file and choose the correct method of reading in the data. Additionally, {rio} allows us to read and write directly from and to .zip files.\n# Import data\nimport(\"iris.xlsx\")\n\n# Export data\nexport(iris, \"iris.tsv.zip\")",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#rdata-and-.rda",
    "href": "data.html#rdata-and-.rda",
    "title": "External data",
    "section": ".Rdata and .Rda",
    "text": ".Rdata and .Rda\nWhile working on our analyses, we might come across moments where we want to save some object because it took a long time to create. Or a colleague sent us their data straight from R. In this case, we are working with Rdata files (.Rdata, .Rda). These files are easiest to load into R and export out of R with two specific functions:\n\nload() loads the specified file into R.\nsave() saves an objects onto the device.\n\nWhen we load R data files, we do not need to assign them to an object: the object is stored in the file and automatically restored into the Global Environment. For instance:\n# Save iris to current working directionary\nsave(iris, file = \"~/iris.Rdata\")\n\n# Load iris\nload(\"iris.Rdata\")",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#projectiles-and-carpeting",
    "href": "data.html#projectiles-and-carpeting",
    "title": "External data",
    "section": "Projectiles and carpeting",
    "text": "Projectiles and carpeting\n\nArrow (formerly known as Feather)\nSometimes we might work with files that take a considerable time to process. In such cases, we might prefer alternatives to .csv files and .Rdata files to work with our data faster. In this case, .arrow files come in handily. These files, formerly known as Feather files, are a special memory format that works across any programming language, organized for efficient operations. Working with .arrow files is supported by the {Arrow} package. A quick start to working with Arrow can be found here.\n\n\nParquet\nAlthough fast data is nice, sometimes we just want our data to take up less space. Whereas .arrow files focus on speed, .parquet files focus on efficient data storage and retrieval. Working with .parquet files is also supported by the {Arrow} package and a quick start can again be found here.",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#sql",
    "href": "data.html#sql",
    "title": "External data",
    "section": "SQL",
    "text": "SQL\nSometimes, our data is not stored in a local document, but on a server, such as a SQL (Structured Query Language) server. We can call directly to SQL from R and load data into our Global Environment using {RODBC}, which allows general database access. You can connect to the database with odbcConnect() and then pass SQL queries into data using sqlQuery():\ndat &lt;- sqlQuery(odbcConnect(\"database\"), \"select * from DATA_THAT_IS_DEFINITELY_REAL where SEX LIKE 1\")",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#readily-available-data",
    "href": "data.html#readily-available-data",
    "title": "External data",
    "section": "Readily available data",
    "text": "Readily available data\nR and many available R packages also come with external data that is already available in the packages. To load this data, you can use data():\ndata(iris)\nAdditionally, you can get an overview of all available data in the available packages using data().",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#exercises",
    "href": "data.html#exercises",
    "title": "External data",
    "section": "Exercises",
    "text": "Exercises\n\n0. Downloading data\nFor these exercises, we will work with some freely available data that you can download here. If the link does not work, you can look for the file State funded schools inspections and outcomes as at 31 December 2022 here.\n\n\n1. Loading new data\nLoad the data you just downloaded into a variable called dat.\n\n\nAnswer\n# Load necessary packages\npacman::p_load(\"rio\", \"readr\")\n\n# Define file so that I only have to type it once for each example\nfile &lt;- \"C:/users/rjjanse.LUMCNET/downloads/State_funded_schools_inspections_and_outcomes_as_at_31_December_2022.csv\"\n\n# Answer 1: using import\ndat &lt;- import(file)\n\n# Answer 2: using read_csv\n# suppressWarnings and show_col_types = FALSE for clean output\ndat &lt;- suppressWarnings(read_csv(file, show_col_types = FALSE))\n\n# Answer 3: using read.csv\ndat &lt;- read.csv(file)\n\n\n\n\n2. Storing data\nNow save the data to a file called example_data.Rdata.\n\n\nAnswer\n# Answer 1: use save()\nsave(dat, file = \"example_data.Rdata\")\n\n# Answer 2: use export()\nexport(dat, \"example_data.Rdata\")",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "data.html#next-topic",
    "href": "data.html#next-topic",
    "title": "External data",
    "section": "Next topic",
    "text": "Next topic\nNow that we know are armed with the power of packages and the ability to load data, let’s explore one of the most famous packages for R: the Tidyverse!\nNext: Tidyverse",
    "crumbs": [
      "The basics",
      "External data"
    ]
  },
  {
    "objectID": "dplyr.html",
    "href": "dplyr.html",
    "title": "Dplyr",
    "section": "",
    "text": "{dplyr}, a combination of data and plier, is a package that allows manipulation of data in an easy and efficient way. Whether you want to drop columns, drop rows, create new variables, or change old variables, {dplyr} allows you to do this in an intuitive way which requires little code (especially compared to base R). If you have not already installed and loaded {dplyr}, you can do so with:\n\n# Load dplyr\npacman::p_load(\"dplyr\")\n\nIn this section, we will work with the starwars dataset, that is automatically loaded in when you load {dplyr}.\n\n# Show first 5 rows of starwars\nhead(starwars, n = 5)\n\n# A tibble: 5 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nLet’s load the starwars data into our Global Environment so that we can easily access it:\n\n# Load starwars into Global Environment object called sw\nsw &lt;- starwars\n\nAll {dplyr} functions that take a data frame or tibble start with the .data argument. Therefore, in all examples below, we first specify our .data as sw before supplying arguments of the function.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#dplyr",
    "href": "dplyr.html#dplyr",
    "title": "Dplyr",
    "section": "",
    "text": "{dplyr}, a combination of data and plier, is a package that allows manipulation of data in an easy and efficient way. Whether you want to drop columns, drop rows, create new variables, or change old variables, {dplyr} allows you to do this in an intuitive way which requires little code (especially compared to base R). If you have not already installed and loaded {dplyr}, you can do so with:\n\n# Load dplyr\npacman::p_load(\"dplyr\")\n\nIn this section, we will work with the starwars dataset, that is automatically loaded in when you load {dplyr}.\n\n# Show first 5 rows of starwars\nhead(starwars, n = 5)\n\n# A tibble: 5 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nLet’s load the starwars data into our Global Environment so that we can easily access it:\n\n# Load starwars into Global Environment object called sw\nsw &lt;- starwars\n\nAll {dplyr} functions that take a data frame or tibble start with the .data argument. Therefore, in all examples below, we first specify our .data as sw before supplying arguments of the function.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#renaming-and-relocating",
    "href": "dplyr.html#renaming-and-relocating",
    "title": "Dplyr",
    "section": "Renaming and relocating",
    "text": "Renaming and relocating\nBefore we can do anything to the data itself, we should make sure we like the names of the variables. Three of the variables contain the word ‘color’ (hair_color, skin_color, eye_color). However, we might think it is intuitive enough that these variables indicate colour, so maybe we want to change those names. For this we can use the function rename(). In rename(), we specify any number of arguments we want, where the left hand side of the argument indicates the new column name and the righth and side of the argument indicates the column that needs to be changed (and therefore the old column name). The right hand side can also be the position of the column (e.g., 2 for the second column).\n\n# Rename variables\nsw &lt;- rename(sw, hair = hair_color, skin = skin_color, eye = eye_color)\n\n\n\n\n\n\n\nMany functions, among which functions in {dplyr} like rename() have an argument called .... This ellipsis simply means that you can supply any number of arguments of the type that the function uses. For rename(), this means we can supply an endless list of variables to be renamed.\n\n\n\nNow our data has some changed names, but we are not done yet. It might also be preferable that sex and gender are mentioned immediately after the name. To do this, we can simply use relocate(). In relocate(), we specify a group of columns and specify before (argument .before) or after (argument .after) which column they should be placed.\n\n# Relocate variables\nsw &lt;- relocate(sw, sex:gender, .after = name)\n\n# This has the same effect\nsw &lt;- relocate(sw, c(sex, gender), .before = height)",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#filtering-and-selecting",
    "href": "dplyr.html#filtering-and-selecting",
    "title": "Dplyr",
    "section": "Filtering and selecting",
    "text": "Filtering and selecting\nNow that our data is a bit more how we (or I?) wanted it, we can also determine whether there are some columns or rows that we do not actually want or need. First of, because I am not interested in any data from outside the starwars universe, we can remove the column films. To do this, we use select(), which allows us to either specify the columns we want to keep, or specify the columns we want to drop. To keep columns, we simply name them and to drop columns we name them with a dash/minus sign before (-).\n\n# Drop films column\nsw &lt;- select(sw, -films)\n\n# This does the same thing\nsw &lt;- select(sw, name:species, vehicles:starships)\n\nAdditionally, I am not interested in any character (i.e., row) of who we do not know the mass or who is from Tatooine. Tatooine is full of sand and I don’t like sand. It’s coarse and rough. To remove rows, we can use the filter() function. In filter(), we supply conditions to which rows must adhere to stay.\n\n# Remove rows with missing mass or with characters from Tatooine\nsw &lt;- filter(sw, !is.na(mass) & !is.na(height) & homeworld != \"Tatooine\")\n\nHere, we use is.na() to see what rows are missing in the column mass and then take the reverse (!). We do the same for height. Additionally (&), the homeworld should not equal (!=) Tatooine.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#mutating-and-conditionals",
    "href": "dplyr.html#mutating-and-conditionals",
    "title": "Dplyr",
    "section": "Mutating and conditionals",
    "text": "Mutating and conditionals\nNow that we have the data that we want, we might want to create some new variables. For instance, it would be interesting to know the Body Mass Index (BMI) of the characters, which we can calculate because we have height and mass. We can do that with mutate(). In this function, we can specify any number of arguments, with the left hand side of the argument being the name of the new variable and the right hand side being the value it should take.\nA great characteristic of mutate() is that we can immediately use a variable we just calculted within the same mutate() function call. For instance, if we calculate BMI, we can immediately create a variable that indicates whether according to commonly used BMI dichotomisation for humans, a character classifies as overweight or not.\n\n# Calculate BMI and overweight indicator\nsw &lt;- mutate(sw, \n             # Change height to meters\n             height = height / 100,\n             # Calculate BMI\n             bmi = mass / height ^ 2,\n             # Create indicator for overweight\n             overweight = ifelse(bmi &gt;= 25, 1, 0))\n\n# Show summary of BMI\nsummary(sw[[\"bmi\"]])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.89   19.48   23.83   32.40   25.86  443.43 \n\n# Show table of overweight\ntable(sw[[\"overweight\"]])\n\n\n 0  1 \n32 16 \n\n\nWhat we used to create the overweight variable was an if-else clause, which is a commonly used clause in programming. Simply, it checks whether a condition is true. If a condition is true, then it does A, otherwise it does B. In this case, ifelse() checks the condition bmi &gt;= 25. If that condition is TRUE, then the variable overweight is assigned a 1, otherwise a 0.\nIf we want to be able to assign more than two values based on a single conditions, we can use two approaches. First, we can nest multiple ifelse() statements. Below, we code a variable weight_status which indicates underweight (BMI &lt; 18, 1), normal weight (BMI 18-25, 2), overweight (BMI &gt;25, 3), and obesity (BMI &gt;30, 4).\n\n# Create new variable weight status\nsw &lt;- mutate(sw, \n             # Create indicator for weight status\n             weight_status = ifelse(bmi &lt; 18, 1,\n                                    ifelse(bmi &gt;= 18 & bmi &lt;= 25, 2,\n                                           ifelse(bmi &gt; 25 & bmi &lt;= 30, 3, 4))))\n\nThis can quickly become unreadable if more groups should be made. Luckily, {dplyr} offers us case_when() and case_match(). Using case_when(), we only need to call one function and then supply all conditions. In case_when() this is written as condition ~ result:\n# Create new variable weight status\nsw &lt;- mutate(sw, \n             # Create indicator for weight status\n             weight_status = case_when(bmi &lt; 18 ~ 1,\n                                       bmi &gt;= 18 & bmi &lt;= 25 ~ 2,\n                                       bmi &gt; 25 & bmi &lt;= 30 ~ 3,\n                                       .default = 4))\nWe also specify .default = 4, which means that any row without a matched condition should receive the value 4. However, be careful if you have missing data, as .default will also fill in those values. If .default is not supplied, any row not matching a condition will get an NA.\ncase_when() is a great function and especially useful for multiple conditions that can be matched based on multiple columns or when we want to use conditions (&gt;, &lt;=, etc). Nonetheless, if we want to use only a single variable and do not need conditions, we can also use case_match(), where first the used variable is specified and then the matches, without having to respecify the variable in every match:\n\n# Create new variable weight status\nsw &lt;- mutate(sw,\n             # Create indicator for weight status\n             weight_status = case_match(species,\n                                        \"Human\" ~ \"Humanoid\",\n                                        \"Yoda's species\" ~ \"Small, green, and wrinkly with pointy ears\",\n                                        .default = species))",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#working-across-columns",
    "href": "dplyr.html#working-across-columns",
    "title": "Dplyr",
    "section": "Working across columns",
    "text": "Working across columns\nThere might be a case where we want to change all numeric variables to character. In such case, we could write an extensive mutate argument as follows:\n# Change numerics to character\nsw &lt;- mutate(sw,\n             # Change height\n             height = as.character(height),\n             # Change mass\n             mass = as.character(mass),\n             # Change birth year\n             birth_year = as.character(birth_year),\n             # Change BMI\n             bmi = as.character(bmi))\nEven without the way of annotating that I try to circulate, this code would be unefficient to write. {dplyr} offers us across() to make our lives easier in such cases. With across(), we can apply multiple functions immediately to mulitple columns. If we want to change all those columns to character and check how many characters each has, we could simply do:\n\n# Change numerics to character and show last 7 columns\nmutate(sw, across(c(height, mass, birth_year, bmi), list(char = as.character, charn = nchar)))[18:24]\n\n# A tibble: 48 × 7\n   height_charn mass_char mass_charn birth_year_char birth_year_charn bmi_char  \n          &lt;int&gt; &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;                      &lt;int&gt; &lt;chr&gt;     \n 1            4 32                 2 33                             2 34.722222…\n 2            3 49                 2 19                             2 21.777777…\n 3            4 77                 2 57                             2 23.245984…\n 4            4 112                3 200                            3 21.545090…\n 5            3 80                 2 29                             2 24.691358…\n 6            4 74                 2 44                             2 24.725182…\n 7            4 1358               4 600                            3 443.42857…\n 8            3 77                 2 21                             2 26.643598…\n 9            3 110                3 &lt;NA&gt;                          NA 33.950617…\n10            3 75                 2 82                             2 25.951557…\n# ℹ 38 more rows\n# ℹ 1 more variable: bmi_charn &lt;int&gt;",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#the-pipe",
    "href": "dplyr.html#the-pipe",
    "title": "Dplyr",
    "section": "The pipe: %>%",
    "text": "The pipe: %&gt;%\nBefore we continue with other useful {dplyr} functions, we should talk about the pipe operator %&gt;%. Although %&gt;% is not originally from {dplyr} but instead imported from {magrittr} that we will discuss after this section.\nNormally, if we wanted to apply multiple functions at the same time (for instance, filter() and select() after one another), we would nest the functions:\n\n# Keep only the birth year column and then keep only birth years above 100\nfilter(select(starwars, birth_year), birth_year &gt; 100)\n\n# A tibble: 5 × 1\n  birth_year\n       &lt;dbl&gt;\n1        112\n2        200\n3        600\n4        896\n5        102\n\n\nHowever, this quickly becomes unreadable. With %&gt;%, we can transform this into more readable code. What %&gt;% does is that it takes the outputted result from the previous function and feeds it into an argument in the next function called .data or data (if this argument is available). We will go into more detail in {magrittr}.\nSo, with %&gt;%, we can rewrite the above code as:\n\n# Take starwars data\nstarwars %&gt;%\n    # Keep only birth year column\n    select(birth_year) %&gt;%\n    # Keep only birth years above 100\n    filter(birth_year &gt; 100)\n\n# A tibble: 5 × 1\n  birth_year\n       &lt;dbl&gt;\n1        112\n2        200\n3        600\n4        896\n5        102\n\n\n\n\n\n\n\n\nSome more about annotation: with pipe operators, we can make our code much clearer and with that also our annotations. My personal preference is to annotate each new function after a pipe, so that it becomes even more readable. These annotations might just describe what we are doing, or give more details about why we are doing it. This makes it understandable to people who might not understand R equally well or know the functions we are using and allows better understanding of choices we made.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#grouping-and-slicing",
    "href": "dplyr.html#grouping-and-slicing",
    "title": "Dplyr",
    "section": "Grouping and slicing",
    "text": "Grouping and slicing\nNow that we know about pipe operators, we can apply them to some nice {dplyr} functions. Sometimes, we might want to calculate some statistics per group in our data. To do this, we can group the data on the variable(s) that define the groups and then run our analyses. Before we group, we must make sure the data are sorted so that all variables are already ordered in groups. We can do this with arrange(), which arranges variables in the order that you supply them to the function. If you want to arrange a variable in descending order, you can wrap it in desc(). Subsequently, we make the groups with group_by(), which makes groups in the order that the variables are supplied. When we are done working in the groups, we can ungroup the data again with ungroup(). For example, if we want to calculate the mean BMI per sex, we can do the following:\n\n# Calculate mean BMI in strata of sex\nsw &lt;- sw %&gt;%\n    # Arrange for grouping\n    arrange(sex) %&gt;%\n    # Group on sex\n    group_by(sex) %&gt;%\n    # Calculate mean BMI\n    mutate(mean_bmi = mean(bmi)) %&gt;%\n    # Ungroup again\n    ungroup()\n\nHowever, I am actually interested in the mean BMI per groups of sex and gender and only want to keep one row per group. For this, we can use slice(), which allows us subset rows based on their position.\n\n# Calculate mean BMI in strata of sex\nsw %&gt;%\n    # Arrange for grouping\n    arrange(sex, gender) %&gt;%\n    # Group on sex and then gender\n    group_by(sex, gender) %&gt;%\n    # Calculate mean BMI\n    mutate(mean_bmi = mean(bmi)) %&gt;%\n    # Keep one row per group\n    slice(1L) %&gt;%           # Note that 1L means that 1 is an integer\n    # Ungroup again\n    ungroup() %&gt;%\n    # Keep only sex, gender, and mean BMI\n    select(sex, gender, mean_bmi)\n\n# A tibble: 5 × 3\n  sex            gender    mean_bmi\n  &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt;\n1 female         feminine      17.8\n2 hermaphroditic masculine    443. \n3 male           masculine     24.6\n4 none           masculine     34.7\n5 &lt;NA&gt;           &lt;NA&gt;          24.6\n\n\nslice() is a general function but has some more specifications such as slice_head() and slice_tail() which you can read about in the slice() help function (?slice).\n\nGrouping functions\nWhen we group our data, we can also extract some metadata about the groups we created with the following functions:\n\ngroup_data(): metadata that defines the grouping structure\ngroup_keys(): metadata that describes the groups\ngroup_rows(): location of the rows in the original data per group\ngroup_indices(): a vector with the group to which each row belongs\ngroup_vars(): names of the grouping variables as a character\ngroups(): names of the grouping variables as a list\ngroup_size(): size of each group\nn_groups(): the number of groups",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#summarising-groups",
    "href": "dplyr.html#summarising-groups",
    "title": "Dplyr",
    "section": "Summarising groups",
    "text": "Summarising groups\nOf course it is great to be able to calculate variables within groups, but there is an easier way to quickly get information on a group level with summarise(). This function creates a new data frame with any summary statistic that we specify per group. For instance, to calculate the mean and standard deviation of the birth year and the proportion of individuals without hair per planet, we can do:\n\n# Use starwars\nsw %&gt;%\n    # Arrange for grouping\n    arrange(sex) %&gt;%\n    # Group on sex\n    group_by(sex) %&gt;%\n    # Calculate summary statistics\n    summarise(# Mean\n              mean = mean(birth_year, na.rm = TRUE),\n              # Standard deviation\n              sd = sd(birth_year, na.rm = TRUE),\n              # Proportion of no hair\n              prop_no_hair = sum(hair == \"none\", na.rm = TRUE) / n())\n\n# A tibble: 5 × 4\n  sex             mean    sd prop_no_hair\n  &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 female          42.2  14.5        0.375\n2 hermaphroditic 600    NA          0    \n3 male            57.6  42.5        0.6  \n4 none            33    NA          0    \n5 &lt;NA&gt;           NaN    NA          0.333\n\n\n\n\nThe code for calculating the proportion of no hair was kindly supplied by Vera Broek.\nNote that the NAs in the output result from the fact that we cannot take the standard deviation of a single observation. One of the functions we used was n(). This is one of the context functions supplied by {dplyr}, which allows us to quickly compute a group-specific variable. The available context functions are:\n\nn(): the number of rows/observations in the group\ncur_group(): the group keys (grouping variables)\ncur_group_id(): gives the group a unique identifier\ncur_group_rows(): gives the row indices in the ungrouped data for the current group\ncur_column(): gives the name of the current column (only works in across())\n\n\nCount and tally\ntally() and count() are two wrappers around summarise:\n\ntally() is equal to summarise but automatically calls n() (if it’s the first tally) or sum() (if it’s the second tally), and therefore an easy shorthand for summarise(n = n()).\ncount() is equal to group_by() followed by summarise(n = n()) and closed with ungroup().",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#joins",
    "href": "dplyr.html#joins",
    "title": "Dplyr",
    "section": "Joins",
    "text": "Joins\nThere might be times where we work with data that is stored in different data sets. If we want to combine these data sets, e.g., x and y, into one bigger data set, we will often want to do this on the basis of one or more variables, such as a unique study participant identifier and/or a visit number. In this case, we can use joins from {dplyr}, which offers four joins. These joins all add the data together, but differ in what they do with individuals that are not matched in either dataset.\n\n\n\n\n\n\n\n\nFunction\nWill keep all observations in\nCan drop observations in\n\n\n\n\ninner_join()\nneither\nx and y\n\n\nleft_join()\nx\ny\n\n\nright_join()\ny\nx\n\n\nfull_join()\nx and y\nneither\n\n\n\nTo use a join function, we use a pipe operator after the data we want to be joined on (x) and then specify on what column we want to join the data.\n# Get some columns from starwars\nstarwars_x &lt;- starwars[, 1:3]\n\n# Get some more columns from starwars\nstarwars_y &lt;- starwars[, c(1, 4:6)]\n\n# Join data together based on the name\nstarwars_z &lt;- starwars_x %&gt;%\n    # Join some more columns from starwars\n    left_join(starwars_y, \"name\")\nIf we would want to join on more columns than only name, we can put the joining columns in a vector with c().",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#understanding-pipelines",
    "href": "dplyr.html#understanding-pipelines",
    "title": "Dplyr",
    "section": "Understanding pipelines",
    "text": "Understanding pipelines\nWith the {dplyr} functions we have seen so far, we can manipulate our data quite easily and quickly. However, it might be confusing what some functions do, especially when a longer pipeline (i.e., multiple pipe operators) is used, such as the below example. If we want to better understand, we could run the code line for line and view the data frame to get a better understanding. However, external tools are also available to help us.\n# Extensive pipeline\nstarwars %&gt;%\n    # Arrange for grouping\n    arrange(sex) %&gt;%\n    # Group on sex\n    group_by(sex) %&gt;%\n    # Create new variable BMI based on mass and height\n    mutate(bmi = mass / (height / 100) ^ 2) %&gt;%\n    # Drop individuals with missing BMI\n    filter(!is.na(bmi))\n\nTidy data tutor\nWith tidy data tutor, we can run your pipeline on data that can be loaded into R from packages, such as starwars from {dplyr}, and visualize what happens at each pipe operator. We can simply paste the pipeline and load in available data and run it to get a visualization. An example for the above code can be found here.\n\n\nMicrosoft datamations\nAnother possibliity is {datamations}, which gives us animations of how the pipeline operates. To use {datamations}, you can first install it with:\n# Install datamations from github\ndevtools::install_github(\"microsoft/datamations\")\nNext, we can write your pipeline as you normally would. Subsequently, we put the whole pipeline between apostrophes to turn it into a string and use datamation_sanddance() to generate the animation:\n\"# Pipeline\nstarwars %&gt;%\n    # Remove hermaphroditic sex as this gives a large outlier\n    filter(sex != 'hermaphroditic') %&gt;%\n    # Calculate BMI\n    mutate(bmi =mass / (height / 100) ^ 2) %&gt;%\n     # Group on sex\n    group_by(sex) %&gt;%\n    # Get mean BMI per group\n    summarise(mean_bmi = mean(bmi))\" %&gt;% \n    # Get animation\n    datamation_sanddance()\nNote that {datamations} cannot use every {dplyr} function however. More information on {datamations} can be found here.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#other-useful-functions",
    "href": "dplyr.html#other-useful-functions",
    "title": "Dplyr",
    "section": "Other useful functions",
    "text": "Other useful functions\nWe now discussed some of the most useful functions in {dplyr}, but there are other useful functions available. This list is not meant to make you remember everything, but more so to introduce you to them once, so that you might recognize when you are trying to perform an operation for which {dplyr} has an efficient implementation. Moreover, this list is not exhaustive, but just a selection of useful functions; for everything available in {dplyr}, see here.\n\nSelecting parts of our data\n\npull(): we can extract a single column with pull(), which is similar to subsetting with the $ operator.\npick(): if we are inside a function such as mutate() or summarise(), we can use pick() to subset multiple columns.\nslice_sample(): select random rows. This is especially useful if you have a rather large data set and first want to test your code on a random subset of your data before running it on the complete data, which might take longer.\ndistinct(): keep only one row per unique combination of columns supplied to the function. This function drops all columns not specified, unless .keep_all = TRUE.\n\n\n\nGetting information on and in our data\n\nlag(): take a column’s value from the previous row (will be NA for the first row).\nlead(): take a column’s value from the next row (will be NA for the last row).\nfirst(), last(), and nth(): take the first, last, or nth (can be specified in the function) value in a column.\nn_distinct(): count the total number of unique values.\nglimpse(): get a quick glimpse of your data, similar to pressing on the blue button in front of the data in the global environment.\n\n\n\nManipulating our data\n\nrows(): perform row-based modifications on a data frame using information in another data frame. See ?rows for a detailed explanation.\nbind_rows(): add data frames together based on rows. This is a more efficient implementation of rbind() and does not require the different data frames to all have the same columns (the final data frame will have all columns of the individual data frames that are bound).\nbind_cols(): similar to bind_rows() but for columns, improving on cbind().\nrowwise(): perform a function per row in the data. This is useful when a vectorized function (i.e., a function that operates over the entire vector) is not available. For more detailed explanation, see ?rowwise.\nna_if(): replace a certain value y in vector x with NA.\nif_else(): an improved version of ifelse() that can also take into account missings.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#extensions",
    "href": "dplyr.html#extensions",
    "title": "Dplyr",
    "section": "Extensions",
    "text": "Extensions\n\n{dtplyr}\n{data.table} is a package that works with data frames at a much higher speed than other R packages. Although {data.table} is discussed in more detail in another section, here we shortly discuss the {dplyr} integration with {data.table}.\nWe can use lazy_dt() to create a data table that tracks any operations and then transform it using as.data.table(), as.data.frame(), or as_tibble().\nAlthough {dtplyr} is not as fast as {data.table}, it does allow using the readable {dplyr} while approaching the speed of {data.table}.\n\n\n{dbplyr}\nSometimes, our data is not stored locally but in a remote database, such as SQL. In that case, you can use {dbplyr} to manipulate the data as if it were in-memory using {dplyr} functionality.\nUsing the dbConnect() from {DBI}, we can connect a data base from SQL to an object in R and then manipulate it. Behind the scenes, your R code is translated into SQL code. To get started, you can look up the vignette (vignette(sql)) or see here and here.\n\n\n{sparklyr}\nApache Spark is a powerful framework for processing data quickly and efficiently. It is popular due to it’s speed with big data. Although not officially a {dplyr} extension, {dplyr} and other R code can be used to access Apache Spark through {sparklyr}. You can find more information here.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#wrapping-up",
    "href": "dplyr.html#wrapping-up",
    "title": "Dplyr",
    "section": "Wrapping up",
    "text": "Wrapping up\nWe now saw the majority of functions that {dplyr} offers us to manipulate our data into taking the shape we want it to take. If you ever want to have a quick look at what functions are available again, without the explanations in this tutorial, you can check out the {dplyr} reference guide or the documentation.",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#exercises",
    "href": "dplyr.html#exercises",
    "title": "Dplyr",
    "section": "Exercises",
    "text": "Exercises\n\n1. Subset data\nFrom the data mtcars, keep only cars with a weight (wt) of 3 or higher and store this into an object dat\n\n\nAnswer\ndat &lt;- filter(mtcars, wt &gt;= 3)\n\n\n\n\n2. Create weight category\nCreate a column wt_cat categorizing wt into smaller than 4 (0) and 4 or greater (1) in dat.\n\n\nAnswer\n# Solution 1: using ifelse\ndat &lt;- mutate(dat, wt_cat = ifelse(wt &lt; 4, 0, 1))\n\n# Solution 2: using if_else\ndat &lt;- mutate(dat, wt_cat = if_else(wt &lt; 4, 0, 1))\n\n# Solution 3: using case_when\ndat &lt;- mutate(dat, wt_cat = case_when(wt &lt; 4 ~ 0, .default = 1))\n\n\n\n\n3. Drop columns\nRemove the hp and vs columns from dat.\n\n\nAnswer\ndat &lt;- select(dat, -c(hp, vs))\n\n\n\n\n4. Get group statistics\nDetermine the number of cars for each level of cyl\n\n\nAnswer\n# Solution 1: using group_by and summarise\ndat %&gt;%\n    # Arrange data for grouping\n    arrange(cyl) %&gt;% \n    # Group per level of cylinders\n    group_by(cyl) %&gt;% \n    # Get count per level of cylinders\n    summarise(n = n())\n\n\n# A tibble: 3 × 2\n    cyl     n\n  &lt;dbl&gt; &lt;int&gt;\n1     4     2\n2     6     4\n3     8    14\n\n\nAnswer\n# Solution 2: using group_by and tally\ndat %&gt;%\n    # Arrange for grouping\n    arrange(cyl) %&gt;%\n    # Group per level of cylinders\n    group_by(cyl) %&gt;%\n    # Tally per group of cylinders\n    tally()\n\n\n# A tibble: 3 × 2\n    cyl     n\n  &lt;dbl&gt; &lt;int&gt;\n1     4     2\n2     6     4\n3     8    14\n\n\nAnswer\n# Solution 3: using count\ndat %&gt;%\n    # Arrange for grouping\n    arrange(cyl) %&gt;%\n    # Count per group of cylinders\n    count(cyl)\n\n\n  cyl  n\n1   4  2\n2   6  4\n3   8 14\n\n\nAnswer\n# Solution 4: using gropu_by and mutate\ndat %&gt;%\n    # Arrange for grouping\n    arrange(cyl) %&gt;%\n    # Group per level of cylinders\n    group_by(cyl) %&gt;%\n    # Per group, calculate number of cylinders\n    mutate(n = n()) %&gt;%\n    # Per group, keep one row\n    slice(1L) %&gt;%\n    # Ungroup again\n    ungroup() %&gt;%\n    # Keep only relevant columns\n    select(cyl, n)\n\n\n# A tibble: 3 × 2\n    cyl     n\n  &lt;dbl&gt; &lt;int&gt;\n1     4     2\n2     6     4\n3     8    14\n\n\n\n\n5. Put it all in a pipeline\nNow perform exercises 1 through 4 but use one continuous pipeline\n\n\nAnswer\n# You can combine any of the solutions of exercise 1 through 4, here I show just one:\ndat &lt;- mtcars %&gt;%\n    # Keep only cars with weight &gt;= 3\n    filter(wt &gt;= 3) %&gt;%\n    # Create category for weight\n    mutate(wt_cat = ifelse(wt &lt; 4, 0, 1)) %&gt;%\n    # Remove columns hp and vs\n    select(-c(hp, vs)) %&gt;%\n    # Arrange for grouping\n    arrange(cyl) %&gt;%\n    # Count per group of cylinders\n    count(cyl)",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "dplyr.html#next-topic",
    "href": "dplyr.html#next-topic",
    "title": "Dplyr",
    "section": "Next topic",
    "text": "Next topic\nNow that we know the grammar of {dplyr}, we can see how {tidyr} assists us if the data we want to manipulate is not quite tidy enough yet.\nNext: Tidyr",
    "crumbs": [
      "Into the tidyverse",
      "Dplyr"
    ]
  },
  {
    "objectID": "magrittr.html",
    "href": "magrittr.html",
    "title": "Magrittr",
    "section": "",
    "text": "{magrittr} is a package that allows us to perform more operations within a timeline to make our code more efficient to write and to read. Its main implementation is the pipe (%&gt;%) which we already discussed in Dplyr. However, it also offers as a number of aliases to make operators available in our pipelines.",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#magrittr",
    "href": "magrittr.html#magrittr",
    "title": "Magrittr",
    "section": "",
    "text": "{magrittr} is a package that allows us to perform more operations within a timeline to make our code more efficient to write and to read. Its main implementation is the pipe (%&gt;%) which we already discussed in Dplyr. However, it also offers as a number of aliases to make operators available in our pipelines.",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#and",
    "href": "magrittr.html#and",
    "title": "Magrittr",
    "section": ". and `",
    "text": ". and `\nBefore we get into the aliases offered by {magrittr}, we should realize that we can do without these aliases by using dots (.) and backticks (`). Here, the dot indicates the data in its current form (i.e. after all previous operations have been applied) and the backticks are put around the operator (e.g. +). The operator is then treated as a function (i.e. parentheses are required).\nFor instance, take the below data frame:\n\n# Create example data\nvec_fib &lt;- c(1, 1, 2, 3, 5, 8, 13, 21, 34, 55)\n\nIf we want to subtract 3 from all numbers, multiply by 1.5, and then set all negative values to NA, we could do the following:\n\n# First, load magrittr\npacman::p_load(\"magrittr\")\n\n# Start pipeline with vector\nvec_fib %&gt;%\n    # Subtract 3\n    `-`(3) %&gt;%\n    # Multiply by 1.5\n    `*`(1.5) %&gt;%\n    # Set all negative values to NA\n    ifelse(. &lt; 0, NA, .)\n\n [1]   NA   NA   NA  0.0  3.0  7.5 15.0 27.0 46.5 78.0",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#aliases",
    "href": "magrittr.html#aliases",
    "title": "Magrittr",
    "section": "Aliases",
    "text": "Aliases\nHowever, by using {magrittr} allows us functions instead of these operators that improve readability of the code and are easier to use, which are called the aliases. Using those aliase, we would write the above code as:\n\n# Start piepline with vector\nvec_fib %&gt;%\n    # Subtract 3\n    subtract(3) %&gt;%\n    # Multiply by 1.5\n    multiply_by(1.5) %&gt;%\n    # Set all negative values to NA\n    # Here, the alias is perhaps not as useful, as we use . &lt; 0 in a function. The aliases are mostly useful as first function in each piece of the pipeline\n    ifelse(is_less_than(., 0), NA, .)\n\n [1]   NA   NA   NA  0.0  3.0  7.5 15.0 27.0 46.5 78.0\n\n\nThe available aliases (also available here or in the help function of each alias in R) are:\n\n\n\nDescription\nSymbol\n\n\n\n\nextract2\n`[[`\n\n\ninset\n`[&lt;-`\n\n\ninset2\n`[[&lt;-`\n\n\nuse_series\n`$`\n\n\nadd\n`+`\n\n\nsubtract\n`-`\n\n\nmultiply_by\n`*`\n\n\nraise_to_power\n`^`\n\n\nmultiply_by_matrix\n`%*%`\n\n\ndivide_by\n`/`\n\n\ndivide_by_int\n`%/%`\n\n\nmod\n`%%`\n\n\nis_in\n`%in%`\n\n\nand\n`&`\n\n\nor\n`|`\n\n\nequals\n`==`\n\n\nis_greater_than\n`&gt;`\n\n\nis_weakly_greater_than\n`&gt;=`\n\n\nis_less_than\n`&lt;`\n\n\nis_weakly_less_than\n`&lt;=`\n\n\nnot (n’est pas)\n`!`\n\n\nset_colnames\n`colnames&lt;-`\n\n\nset_rownames\n`rownames&lt;-`\n\n\nset_names\n`names&lt;-`\n\n\nset_class\n`class&lt;-`\n\n\nset_attributes\n`attributes&lt;-`\n\n\nset_attr\n`attr&lt;-`",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#section",
    "href": "magrittr.html#section",
    "title": "Magrittr",
    "section": "|>",
    "text": "|&gt;\nBesides the pipe implemented by {magrittr}, R also offers a native pipe: |&gt;. Instead of existing data being called by the dot (.), you can use a low dash (_). Although in general the pipes function the same, there are some differences in what they can do and how they are used. The tidyverse has a more elaborate explanation on this topic here and more details are also available here and here.",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#other-pipes",
    "href": "magrittr.html#other-pipes",
    "title": "Magrittr",
    "section": "Other pipes",
    "text": "Other pipes\nThe %&gt;% pipe is not the only pipe {magrittr} offers us.\n\n%T&gt;%\nThe Tee pipe returns the left-hand side of the value instead of the right-hand side. In other words, it returns the input into the function instead of the output of the function. This is helpful when we are only interested in the side-effects of a function, instead of its main output (e.g. printing in console).\nImagine we are interested in only the description of a .csv file, but not actually loading it into our global environment. In that case, I could use the read_csv() function from {readr} with the Tee pipe:\n\n# Load readr\npacman::p_load(\"readr\")\n\n# Get information on .csv file available online\n\"https://drive.google.com/uc?id=1zO8ekHWx9U7mrbx_0Hoxxu6od7uxJqWw&export=download\" %T&gt;% \n    # Print only data information\n    read_csv()\n\nRows: 100 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (10): Customer Id, First Name, Last Name, Company, City, Country, Phone...\ndbl   (1): Index\ndate  (1): Subscription Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n[1] \"https://drive.google.com/uc?id=1zO8ekHWx9U7mrbx_0Hoxxu6od7uxJqWw&export=download\"\n\n\n\n\n%$%\nThe exposition pipe gives the names of the data to the next function, which is especially useful if the function does not have a data argument, such as table():\n\n# Just piping iris into table will not work (commented out to prevent error)\n# iris %&gt;% table(Species)\n\n# Using an exposition pipe, it will work\niris %$% table(Species)\n\nSpecies\n    setosa versicolor  virginica \n        50         50         50 \n\n\n\n\n$&lt;&gt;$\nThe assignment pipe is a shorthand pipe for a pipeline that assigns the final value back into the object that was used as the start of the pipeline (i.e. it is short for x &lt;- x %&gt;% ...). For example:\n\n# Starting value\nx &lt;- 5; y &lt;- 5\n\n# With the assignment operator\nx &lt;- x %&gt;%\n    # Divide by 2\n    divide_by(2)\n\n# With the assignment pipe\ny %&lt;&gt;%\n    # Divide by 2\n    divide_by(2)\n\n# Check whether results are equal\nx == y\n\n[1] TRUE",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#exercises",
    "href": "magrittr.html#exercises",
    "title": "Magrittr",
    "section": "Exercises",
    "text": "Exercises\n\n1. Use aliases to change values\nFrom the starwars dataset (available in {dplyr}, ), extract the column height and divide by 100.\n\n\nAnswer\n# Load dplyr for data\npacman::p_load(\"dplyr\")\n\n# Start pipe with starwars data\nstarwars %&gt;%\n    # Extract column height (unnamed)\n    extract2(\"height\") %&gt;%\n    # Divide by 100\n    divide_by(100)\n\n\n [1] 1.72 1.67 0.96 2.02 1.50 1.78 1.65 0.97 1.83 1.82 1.88 1.80 2.28 1.80 1.73\n[16] 1.75 1.70 1.80 0.66 1.70 1.83 2.00 1.90 1.77 1.75 1.80 1.50   NA 0.88 1.60\n[31] 1.93 1.91 1.70 1.85 1.96 2.24 2.06 1.83 1.37 1.12 1.83 1.63 1.75 1.80 1.78\n[46] 0.79 0.94 1.22 1.63 1.88 1.98 1.96 1.71 1.84 1.88 2.64 1.88 1.96 1.85 1.57\n[61] 1.83 1.83 1.70 1.66 1.65 1.93 1.91 1.83 1.68 1.98 2.29 2.13 1.67 0.96 1.93\n[76] 1.91 1.78 2.16 2.34 1.88 1.78 2.06   NA   NA   NA   NA   NA\n\n\n\n\n2. Use different pipes to meddle with starwars\nNow, reassign a frequency table of species to the object name starwars of individuals of at least 2 meters tall using the pipe operators from {magrittr}.\n\n\nAnswer\n# Start pipe with starwars data and immediately reassign\nstarwars %&lt;&gt;%\n    # Keep only individuals above 2 meters tall\n    filter(height &gt;= 200) %$%\n    # Get table of species\n    table(species)\n\n# Check result\nstarwars\n\n\nspecies\n   Droid   Gungan    Human  Kaleesh Kaminoan   Pau'an Quermian  Wookiee \n       1        2        1        1        2        1        1        2",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "magrittr.html#next-topic",
    "href": "magrittr.html#next-topic",
    "title": "Magrittr",
    "section": "Next topic",
    "text": "Next topic\nWith that, we discussed a large part of the tidyverse. Although some other packages exist, we discuss these in other sections. Now that we know part of the basic grammar of the tidyverse, we can learn a new set of skills useful for any data analysis.\nNext: Plotting",
    "crumbs": [
      "Into the tidyverse",
      "Magrittr"
    ]
  },
  {
    "objectID": "plotting.html",
    "href": "plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "A lot of analyses are represented by figures in the final papers. Additionally, visualization of data may allow better scrutiny of data patterns. As such, creating figures in R, or ‘plotting’ (because we are making plots).\nThe way plots are created varies, but two large methods stand out. The first we will discuss is implemented by the {ggplot2} package. This package is based on the grammar of graphics, a landmark work on statistical graphics (ergo ‘gg’ for ‘grammr of graphics’). The second method we will discuss is the base R plotting, which is part of the R {graphics} package.\nAs example data, we will use the package {palmerpenguins}, which contains data on 344 penguins from three islands in the Palmer Archipelago, Antarctica (more here).\nWe will also load the {ggplot2} package. The {graphics} package is installed and loaded by default.\n\n# Load packages\npacman::p_load(\"ggplot2\",          # Data visualization\n               \"palmerpenguins\"    # Example data\n               )",
    "crumbs": [
      "New skills",
      "Plotting"
    ]
  },
  {
    "objectID": "plotting.html#plotting-in-r",
    "href": "plotting.html#plotting-in-r",
    "title": "Plotting",
    "section": "",
    "text": "A lot of analyses are represented by figures in the final papers. Additionally, visualization of data may allow better scrutiny of data patterns. As such, creating figures in R, or ‘plotting’ (because we are making plots).\nThe way plots are created varies, but two large methods stand out. The first we will discuss is implemented by the {ggplot2} package. This package is based on the grammar of graphics, a landmark work on statistical graphics (ergo ‘gg’ for ‘grammr of graphics’). The second method we will discuss is the base R plotting, which is part of the R {graphics} package.\nAs example data, we will use the package {palmerpenguins}, which contains data on 344 penguins from three islands in the Palmer Archipelago, Antarctica (more here).\nWe will also load the {ggplot2} package. The {graphics} package is installed and loaded by default.\n\n# Load packages\npacman::p_load(\"ggplot2\",          # Data visualization\n               \"palmerpenguins\"    # Example data\n               )",
    "crumbs": [
      "New skills",
      "Plotting"
    ]
  },
  {
    "objectID": "plotting.html#ggplot2",
    "href": "plotting.html#ggplot2",
    "title": "Plotting",
    "section": "{ggplot2}",
    "text": "{ggplot2}\nBasically, the grammar of graphics provides a foundation that describes how any statistical graphic can be build up, which is based on layers. This layered system gives rise to how the package {ggplot2} allows us to create figures (i.e. plots).\n\nLayer 1: the data\nThe first layer we specify is the data layer. In this layer, we specify our data and the mapping of the aesthetics, meaning we define what our x-axis will portray, the y-axis, what colours, etc. will portray. This first layer is called using ggplot():\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm))\n\n\n\n\n\n\n\n\nHere, we specified the first argument (data = penguins) to be our dataset. For the second argument (mapping = aes()), we supply a function: aes(). This function allows us to specify what will make up the aesthetics of the graph: the x-axis will be ‘body_mass_g’ and the y-axis will be ‘flipper_length_mm’. Because we did not supply any other layer, we can see that the figure remains largely empty, only having some automatically set limits and titles for the axes.\n\n\nLayer 2: the geometries\nNow we can add the geometries. We are offered a large number of geometries by {ggplot2}, with some basics including points, lines, bars, histograms, rectangles, segments, steps, and ribbons. Each geometry is called by a geom_...() function, such as geom_point() and geom_line().\nFor our figure, we will add points.\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n    # Geometries\n    geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nYou may notice that layers in these plots are added together by using a plus (+) sign. Additionally, the warning you is just {ggplot2} telling you there were some NA’s that could not be drawn in the plot. Note that this error is also given if you have some values that are outside of the boundaries of your plot.\nWithin each geometry, we can edit many things, such as the colour, fill (i.e. the colour of shapes that contain an inside), size, alpha (i.e. transparency), and shape (or linetype for lines). Much more is possible, but can be learned from the help functions for each geometry.\nNote that any geometry is applied in subsequent order. If we add a trendline (geom_smooth(method = \"lm\", formula = \"y ~ x\")), this will be drawn on top of the points if we specify it after geom_point() or before if we specify it before geom_point().\nLet’s do this now:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n    # Geometries\n    geom_point(shape = 5) +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", colour = \"#B58900\", fill = \"#B58900\", alpha = 0.3) \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe specified point shape as a number, for which you can find online what different numbers mean. We specified the colour as a hex code, but you can also use the rgb() function for RGB specification, or English language for a number of colours that can be found here. Lastly, we specify the British English colour instead of the American English color. {ggplot2} will accept both, for arguments and for functions (e.g. scale_color_manual() and scale_colour_manual() both exist and do the same thing). We will revert the points back to their default for the remainder of the plot.\n\n\nLayer 3: the scaling\nFor the third layer, we will apply scaling, which means we will edit anything that can be a scale (e.g. axes, colours, fill).\n\n\n\n\n\n\nNote\n\n\n\nNote that we deviate from the grammar of graphics in building our plot. The order in which we specify our layers does not adhere to the grammar of graphics. Luckily, in the background, {ggplot2} ignores this, only keeping the order in which we called geometries for geometries, but for instance not drawing theming prior to geometries, even if we specify so.\n\n\n\nAxes\nIn our current plot, we have two scales: the x-axis and y-axis. We can edit these using scale functions that concur with the scale type (i.e. continuous, discrete, etc.). In our case, both scales are continuous, so we will use scale_x_continuous() and scale_y_continuous(). For other types of scales, we might also use scale_x_discrete(), scale_x_date(), etc.\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", colour = \"#B58900\", fill = \"#B58900\", alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\")) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10))                     \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIn the scale functions, we can give the name of the axis, the limits of the axis, at which points there should be ticks (breaks), and the labels given to each tick.\nOne more thing we can do in the scale functions is determine the expansion. By default, {ggplot2} expands the axes a bit so that the figure does not seem too cropped. Sometimes, however, we might want to remove or change this. If we want to remove this, we can use expand = c(0, 0) in the scaling arguments for each axis:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", colour = \"#B58900\", fill = \"#B58900\", alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10))                     \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAbove we only removed the expansion for the y-axis. We can also change the amount of expansion (by addition or multiplication) by supplying the expansion() function to the expand = argument. We will leave the expansion to its default again while working on our example.\n\n\nAesthetics\nBesides scaling the axes, we can also specify specific scales of our plot. Before we do that, let’s go through the different scales we can define in aes():\n\ncolour (or color): this defines the colour of all geometries. For geometries with an inside area, colour will only colour the outside/circumference.\nfill: this defines the colour of the inside of all geometries.\nlinetype: for any geometry that draws a line, this defines the linetype.\nsize: this determines the line of certain geometries, such as points.\n\nThere are a number of other scales, but these are the most important to understand the basics.\nLet’s stratify the plots by island. To do this, we can specify that colour, fill, and linetype should be different for the different levels of island. We can do this in the aes() function. Note that we will remove the colour and fill specification in geom_smooth() as these are now specified in aes().\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10))                     \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAs you can see, {ggplot2} automatically selected colours for us, as well as create a legend, and perform any statistical operations (such as the LOESS smoother) within groups.\nNow we can use scales to change these scales to our preferences:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))                    \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that we specify aesthetics = in the colour scale, which allows us to use one scale for both colour and fill. Of course, we can also separately specify scale_fill_manual().\nThere are also implementations of well-known palettes for colours, for instance viridis which is a palette distinguishable also for people with the most common types of colourblindness:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_viridis_d(aesthetics = c(\"fill\", \"colour\")) +\n    scale_linetype_manual(values = c(2, 4, 6))                    \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nLinetypes can again be specified as numbers or text, for which a guide can be found here.\n\n\n\nLayer 4: labels\nIn the next layer, we will apply labels to the plot, which includes the title, subtitle, axes labels, and legends.\nFor the axes labels, we can use xlab() and ylab() respectively. We won’t need these as we specified the name already in the scaling function, but they might be useful if you do not need the scale function. The title can be specified using the ggtitle() function, which also allows you to specify a subtitle. Alternatively, this can be done through the labs() function, which allows much more control, such as a tag (for multipanel labels where you want to tag A, B, C, etc.), a caption, and alt text (for accessibility purposes).\nFor the plot we’re building, we will aply a title and a subtitle.\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", \n            subtitle = \"Data from the Palmer Archipelago penguins\")                 \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAdditionally, we can edit the legend by using guide(). guide() let’s us specify details about the legend for each scale that we used. In our case, we used colour, fill, and linetype. Imagine that we wanted to remove the legend for fill (which is combined with linetype and colour because they are based on the same variable), we can simply do:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", \n            subtitle = \"Data from the Palmer Archipelago penguins\") +\n    guides(fill = \"none\")             \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAdditionally, we can specify that we want the legend to take a different form (e.g. colourbar). We can also further modify the legend with guide_legend():\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", \n            subtitle = \"Data from the Palmer Archipelago penguins\") +\n    guides(fill = \"none\",\n           colour = guide_legend(ncol = 2, position = \"bottom\"))             \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that we can also specify guide_legend() within scale functions.\n\n\nLayer 5: coordinates and transformations\n\ncoord_cartesian()\nWe have already seen that we can limit our axes using the limits argument in the scaling functions. However, if we limit our axis too much, data that falls outside of this range will be removed. If we want to limit the axes without data being removed, we can use the arguments xlim = and ylim = in the function coord_cartesian(). As an example:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", subtitle = \"Data from the Palmer Archipelago penguins\") +\n    guides(fill = \"none\",\n           colour = guide_legend(ncol = 2, position = \"bottom\")) +\n    # Transformations\n    coord_cartesian(xlim = c(3000, 5000))             \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNote that now the panel is cropped on the x-axis according to coord_cartesian(), but that our data has remained. This is for instance useful when we have some confidence intervals that become very broad but we do not want to show the range of the y-axis over the whole range of the confidence interval. For now, we will leave it out, but it’s good to have it in our toolbox.\n\n\nfacet_grid() and facet_panel()\nSometimes, instead of using scales, we might want to show different groups using facets. This is where facet_grid() and facet_wrap() come in handy. If we have just one variable on which we want to stratify, we can create facets using facet_wrap():\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", subtitle = \"Data from the Palmer Archipelago penguins\") +\n    guides(fill = \"none\",\n           colour = guide_legend(ncol = 2, position = \"bottom\")) +\n    # Transformations\n    facet_wrap(vars(island))            \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIf we have multiply varialbes, facet_grid() can help us out:\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", subtitle = \"Data from the Palmer Archipelago penguins\") +\n    guides(fill = \"none\",\n           colour = guide_legend(ncol = 2, position = \"bottom\")) +\n    # Transformations\n    facet_grid(rows = vars(species), cols = vars(island))            \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIn the facet functions, you can specify multiple things, including the labels given to the strips at the top and whether the axes should be allowed to differ between plots (which can be useful if you just want to create facets of a lot of histograms to show distributions).\nNote that we still specified our scales such as colour, but that this is not required.\n\n\n\nLayer 6: theme\nThe last layer we will discuss is the theme. {ggplot2} allows us to edit the aesthetics of the plot using theme() and offers some basic themes. For instance, we can just make a simple looking plot using theme_bw():\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, colour = island, fill = island, linetype = island)) +\n    # Geometries\n    geom_point() +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\", , alpha = 0.3) +\n    # Scaling\n    scale_x_continuous(name = \"Body mass (grams)\",\n                       limits = c(2500, 6500),\n                       breaks = seq(2500, 6500, 500),\n                       labels = prettyNum(seq(2500, 6500, 500), big.mark = \",\"),\n                       expand = c(0, 0)) +\n    scale_y_continuous(name = \"Flipper length (millimeters)\",\n                       limits = c(170, 240),\n                       breaks = seq(170, 240, 10)) +\n    scale_colour_manual(values = c(\"darkorange\", \"purple\", \"cyan4\"), aesthetics = c(\"colour\", \"fill\")) +\n    scale_linetype_manual(values = c(2, 4, 6))  +\n    # Labels\n    ggtitle(\"Relation between penguin body mass and flipper length\", subtitle = \"Data from the Palmer Archipelago penguins\") +\n    guides(fill = \"none\",\n           colour = guide_legend(ncol = 2, position = \"bottom\")) +\n    # Aesthetics\n    theme_bw()            \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nCommon errors",
    "crumbs": [
      "New skills",
      "Plotting"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "You have made it to the end of the tutorial! I hope you have learned a lot. Although not everything might stick, this tutorial and the search bar in the upper left hopefully provide an easy way to find back information when you need it.",
    "crumbs": [
      "Recap",
      "Summary"
    ]
  },
  {
    "objectID": "summary.html#you-did-it",
    "href": "summary.html#you-did-it",
    "title": "Summary",
    "section": "",
    "text": "You have made it to the end of the tutorial! I hope you have learned a lot. Although not everything might stick, this tutorial and the search bar in the upper left hopefully provide an easy way to find back information when you need it.",
    "crumbs": [
      "Recap",
      "Summary"
    ]
  },
  {
    "objectID": "summary.html#useful-resources",
    "href": "summary.html#useful-resources",
    "title": "Summary",
    "section": "Useful resources",
    "text": "Useful resources\nNo resource on R will ever be comprehensive, but there are some resources available online for free that are very useful. Here are some you might want to check out:\n\n\n\nResource\nDescription\n\n\n\n\n\nThe Epidemiologist R Handbook\nA more extensive R tutorial with a specific focus on epidemiology\nLink\n\n\nRStudio Education\nA short interactive online tutorial made by the RStudio developers\nLink\n\n\nR Graph Gallery\nMaking plots with {base} and {ggplot2}\nLink\n\n\nThe R Inferno\n‘If you are using R and you think you’re in hell, this is a map for you.’ - Patrick Burns\nLink",
    "crumbs": [
      "Recap",
      "Summary"
    ]
  },
  {
    "objectID": "summary.html#acknowledgements",
    "href": "summary.html#acknowledgements",
    "title": "Summary",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nBesides thanking all authors of R packages who have so meticuously documented their work and all resources that have made me learn R, I specifically want to thank Mark Smeets for his contributions to this tutorial.",
    "crumbs": [
      "Recap",
      "Summary"
    ]
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "R is a great language for statistical programming, but can sometimes be strenuous to work with smoothly. The tidyverse is a collection of packages that aims to make it easier to perform these strenuous operations. This ranges from data manipulation and visualization to working specifically with dates. The tidyverse allows these operations to be done in an easy-to-read and easy-to-write style, with all packages integrating with one another fluently (I swear, this is not an advertisement).\nThere are some packages that form the core of the tidyverse, that are all discussed in this tutorial:\n\n\n\nPackage\nFocususes on\nDiscussed in\n\n\n\n\n{tibble}\nBetter data frames\nTidyverse\n\n\n{dplyr}\nData manipulation\nDplyr\n\n\n{tidyr}\nData tidying\nTidyr\n\n\n{readr}\nReading in data\nData\n\n\n{purr}\nProgramming with functions\nFunctions\n\n\n{stringr}\nWorking with strings\nRegex\n\n\n{ggplot2}\nData visualization\nPlotting\n\n\n{forcats}\nWorking with factors\nPlotting\n\n\n\nBesides these packages, the tidyverse also contains other packages that support these packages or add other functionality.",
    "crumbs": [
      "Into the tidyverse",
      "Tidyverse"
    ]
  },
  {
    "objectID": "tidyverse.html#what-is-the-tidyverse",
    "href": "tidyverse.html#what-is-the-tidyverse",
    "title": "Tidyverse",
    "section": "",
    "text": "R is a great language for statistical programming, but can sometimes be strenuous to work with smoothly. The tidyverse is a collection of packages that aims to make it easier to perform these strenuous operations. This ranges from data manipulation and visualization to working specifically with dates. The tidyverse allows these operations to be done in an easy-to-read and easy-to-write style, with all packages integrating with one another fluently (I swear, this is not an advertisement).\nThere are some packages that form the core of the tidyverse, that are all discussed in this tutorial:\n\n\n\nPackage\nFocususes on\nDiscussed in\n\n\n\n\n{tibble}\nBetter data frames\nTidyverse\n\n\n{dplyr}\nData manipulation\nDplyr\n\n\n{tidyr}\nData tidying\nTidyr\n\n\n{readr}\nReading in data\nData\n\n\n{purr}\nProgramming with functions\nFunctions\n\n\n{stringr}\nWorking with strings\nRegex\n\n\n{ggplot2}\nData visualization\nPlotting\n\n\n{forcats}\nWorking with factors\nPlotting\n\n\n\nBesides these packages, the tidyverse also contains other packages that support these packages or add other functionality.",
    "crumbs": [
      "Into the tidyverse",
      "Tidyverse"
    ]
  },
  {
    "objectID": "tidyverse.html#installing-tidyverse",
    "href": "tidyverse.html#installing-tidyverse",
    "title": "Tidyverse",
    "section": "Installing tidyverse",
    "text": "Installing tidyverse\nTo install all packages of the tidyverse, we can simply run:\n# Install the tidyverse\ninstall.packages(\"tidyverse\")\nor of course:\n\n# Install tidyverse and load core tidyverse\npacman::p_load(\"tidyverse\")\n\n── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package to force all conflicts to \nbecome errors\nHowever, note that loading {tidyverse} only loads the core packages as we see in the output. If we want to load packages from the tidyverse that are not part of the core set, we need to load those packages separately:\n# Load core tidyverse\nlibrary(tidyverse)\n\n# ALso load the magrittr package\nlibrary(magrittr)",
    "crumbs": [
      "Into the tidyverse",
      "Tidyverse"
    ]
  },
  {
    "objectID": "tidyverse.html#shiver-my-timbers-tibbles",
    "href": "tidyverse.html#shiver-my-timbers-tibbles",
    "title": "Tidyverse",
    "section": "Shiver my timbers tibbles",
    "text": "Shiver my timbers tibbles\nAlthough R normally works with data frames, the tidyverse works with tibbles. Tibbles are an enhanced type of data frame that try to accomplish two things:\n\nThey try to do less\nThey complain more\n\nAs stated by the documentation, this is useful because it: “…forces you to confront problems earlier, typically leading to cleaner, more expressive code”.\nTidyverse automatically creates tibbles, but you can also make tibbles yourself. Similar to data.frame() which we saw before, a tibble can be created with tibble(). Additionally, pre-existing data frames can be transformed to tibbles with as_tibble().\nBesides better functionality, tibbles also print cleaner. Compare printing the first 15 rows of the data frame iris to printing all rows of the tibble iris:\n\n# Print first 15 rows of data frame iris\niris[1:15, ]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1           5.1         3.5          1.4         0.2  setosa\n2           4.9         3.0          1.4         0.2  setosa\n3           4.7         3.2          1.3         0.2  setosa\n4           4.6         3.1          1.5         0.2  setosa\n5           5.0         3.6          1.4         0.2  setosa\n6           5.4         3.9          1.7         0.4  setosa\n7           4.6         3.4          1.4         0.3  setosa\n8           5.0         3.4          1.5         0.2  setosa\n9           4.4         2.9          1.4         0.2  setosa\n10          4.9         3.1          1.5         0.1  setosa\n11          5.4         3.7          1.5         0.2  setosa\n12          4.8         3.4          1.6         0.2  setosa\n13          4.8         3.0          1.4         0.1  setosa\n14          4.3         3.0          1.1         0.1  setosa\n15          5.8         4.0          1.2         0.2  setosa\n\n# Print all rows of iris when changed to tibble\nas_tibble(iris)\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows\n\n\nIn tibbles, when printed, numerical values are not called numeric but double. In practice, there is no difference and the class (class(as_tibble(iris)[[\"Sepal.Length\"]]) will still be numerical. More information about column types in tibbles can be found here.",
    "crumbs": [
      "Into the tidyverse",
      "Tidyverse"
    ]
  },
  {
    "objectID": "tidyverse.html#next-topic",
    "href": "tidyverse.html#next-topic",
    "title": "Tidyverse",
    "section": "Next topic",
    "text": "Next topic\nNext, we will take a good look at an important core package of the tidyverse: dplyr.\nNext: Dplyr",
    "crumbs": [
      "Into the tidyverse",
      "Tidyverse"
    ]
  }
]